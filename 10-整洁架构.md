在这最后一章中，我们将重点关注如何在整个系统的设计中整合在一起。这更像是一个理论章节。鉴于该主题的性质，深入研究更底层的细节会太复杂。此外，关键是要避开这些细节，假设前几章探讨的所有原则都被同化，并专注于大规模系统的设计。

本章的主要目标如下：

- 设计可以长期维护的软件系统
- 通过维护质量属性有效地处理软件项目
- 研究应用于代码的所有概念如何与一般系统相关

本章探讨了干净的代码如何演变为干净的架构，相反，干净的代码如何也是良好架构的基石。如果软件解决方案具有质量，它就是有效的。架构需要通过实现质量属性（性能、可测试性、可维护性等）来实现这一点。但是代码还需要在每个组件上启用此功能。

第一部分首先探索代码和架构之间的关系。

## 从整洁代码到整洁架构

本节讨论了在我们考虑大型系统的各个方面时，在前几章中强调的概念如何以略有不同的形式重新出现。这与适用于更详细设计和代码的概念如何也适用于大型系统和体系结构有一个有趣的相似之处。

前几章探讨的概念与单个应用程序相关，通常是一个项目，它可能是源代码控制版本系统 (Git) 的单个（或几个）存储库。这并不是说那些设计思想只适用于代码，或者在思考架构时没有用处，原因有二：代码是架构的基础，如果不仔细编写，无论架构如何深思熟虑，系统都会失败。

其次，前几章中介绍的一些原则不仅适用于代码，而且是设计思想。最明显的例子来自设计模式。它们是高级抽象。有了它们，我们可以快速了解架构中组件的外观，而无需深入了解代码的细节。

但是大型企业系统通常由许多这样的应用程序组成，现在是时候开始考虑分布式系统形式的更大设计了。

在以下各节中，我们将讨论贯穿全书的主要主题，但现在是从整个系统的角度进行讨论。

如果软件架构有效，它就是好的。在一个好的架构中最常见的方面是所谓的质量属性（可扩展性、安全性、性能和耐用性等特征是最常见的）。这是有道理的；毕竟，您希望您的系统能够在不崩溃的情况下处理增加的负载，并且能够在不需要维护的情况下无限期地连续工作，并且可以扩展以支持新的需求。

但是架构的操作方面也使它整洁。可操作性、持续集成以及发布变更的容易程度等特性也会影响系统的整体质量。

### 关注点分离

在一个应用程序中，有多个组件。它们的代码分为其他子组件，例如模块或包，模块分为类或函数，类分为方法。在整本书中，重点一直是让这些组件尽可能小，特别是在函数的情况下——函数应该做一件事并且很小。

提出了几个理由来证明这一理由。小函数更容易理解、遵循和调试。它们也更容易测试。我们代码中的部分越小，为它编写单元测试就越容易。

对于每个应用程序的组件，我们想要不同的特性，主要是高内聚和低耦合。通过将组件分成更小的单元，每个单元都有一个明确的职责，我们实现了一个更好的结构，更容易管理更改。面对新的需求，只有一个正确的地方可以进行更改，其余的代码应该不受影响。

当我们谈论代码时，我们说组件是指这些内聚单元之一（例如，它可能是一个类）。就架构而言，组件意味着系统中可以被视为工作单元的任何东西。组件这个术语本身很模糊，所以在软件架构中没有普遍接受的定义来更具体地说明它的含义。工作单元的概念因项目而异。组件应该能够以自己的周期发布或部署，独立于系统的其余部分。

对于 Python 项目，组件可以是包，但服务也可以是组件。请注意在同一类别下如何考虑具有不同粒度级别的两个不同概念。举个例子，我们在前几章中使用的事件系统可以被认为是一个组件。它们是一个具有明确定义目的的工作单元（丰富从日志中识别的事件）。它们可以独立于其他部分进行部署（无论是作为 Python 包，或者，如果我们将它们的功能公开，作为服务；稍后会详细介绍），并且它们是整个系统的一部分，但不是整个应用程序本身.

在前几章的例子中，我们看到了惯用的代码，我们还强调了良好设计对我们的代码的重要性，具有单一、明确职责的对象被隔离、正交且更易于维护。这同样适用于详细设计（功能、类、方法）的标准，也适用于软件架构的组件。

> 在设计蓝图时，请记住良好的设计原则。

大型系统只是一个组件可能是不可取的。单体应用程序将充当唯一的事实来源，对系统中的一切负责，这将带来许多不希望的后果（更难隔离和识别更改，更难进行有效测试，等等）。

同样，如果我们不小心将所有内容放在一个地方，我们的代码将更难以维护，如果其组件没有得到同等关注，应用程序也会遇到类似的问题。

在系统中创建内聚组件的想法可以有多个实现，这取决于我们需要的抽象级别。

一种选择是识别可能被多次重用的公共逻辑并将其放入 Python 包中（我们将在本章后面讨论详细信息）。

另一种选择是在微服务架构中将应用程序分解为多个较小的服务。这个想法是让组件具有单一且明确定义的职责，并通过使这些服务协作和交换信息来实现与单体应用程序相同的功能。

### 单体应用和微服务

上一节中最重要的想法是分离关注点的概念：不同的职责应该分布在不同的组件中。正如在我们的代码中（更详细的设计级别），拥有一个无所不知的巨型对象并不是一件好事，在我们的架构中，不应该有一个组件拥有一切。

然而，有一个重要的区别。不同的组件并不一定意味着不同的服务。可以将应用程序划分为更小的 Python 包（我们将在本章稍后介绍打包）并创建由许多依赖项组成的单个服务。

将职责分离到不同的服务中是一个好主意，它有一些好处，但也是有代价的。

如果存在需要跨多个其他服务重用的代码，典型的响应是将其封装到微服务中，以供公司中的许多其他服务调用。这不是重用代码的唯一方法。考虑将该逻辑打包为由其他组件导入的库的可能性。当然，这只有在所有其他组件都使用相同语言编写时才可行；否则，是的，微服务模式是唯一的选择。

微服务架构具有完全解耦的优势：不同的服务可以用不同的语言或框架编写，甚至可以独立部署。它们也可以单独进行测试。这是有代价的。他们还需要一份强有力的合同让客户知道如何与此服务交互，并且他们还分别受服务级别协议 (SLA) 和服务级别目标 (SLO) 的约束。

它们还会增加延迟：必须调用外部服务来获取数据（无论是通过 HTTP 还是 gRPC）都会对整体性能造成影响。

由较少服务组成的应用程序更加僵化，无法独立部署。它甚至可能更加脆弱，因为它可能成为单点故障。另一方面，它可能更高效（因为我们避免了昂贵的 I/O 调用），并且我们仍然可以通过使用 Python 包实现组件的良好分离。

本节的重点是在创建新服务或使用 Python 包之间思考正确的架构风格。

### 抽象

这就是封装再次出现的地方。当涉及到我们的系统时（就像我们在代码方面所做的那样），我们想就域问题进行讨论，并尽可能隐藏实现细节。

以同样的方式，代码必须具有表现力（几乎达到自文档化的程度）并具有正确的抽象来揭示基本问题的解决方案（最小化意外复杂性），架构应该告诉我们系统是关于什么的.诸如用于将数据保存在磁盘上的解决方案、选择的 Web 框架、用于连接到外部代理的库以及系统之间的交互等细节并不相关。相关的是系统做什么。尖叫架构 (SCREAM) 等概念反映了这一想法。

在第 4 章 SOLID 原则中解释的依赖倒置原则 (DIP) 在这方面有很大帮助；我们不想依赖于具体的实现，而是依赖于抽象。在代码中，我们将抽象（或接口）放置在边界、依赖项、应用程序的那些我们无法控制且将来可能会更改的部分上。我们这样做是因为我们想要反转依赖关系，让它们必须适应我们的代码（必须遵守接口），而不是相反。

创建抽象和反转依赖项是很好的做法，但还不够。我们希望我们的整个应用程序独立于我们无法控制的事物。这不仅仅是用对象抽象——我们需要抽象层。

就详细设计而言，这是一个微妙但重要的区别。例如，在 DIP 中，建议创建一个可以使用标准库中的 abc 模块实现的接口。因为 Python 与鸭子类型一起工作，虽然使用抽象类可能会有所帮助，但它不是强制性的，因为只要符合所需的接口，我们就可以轻松地使用常规对象实现相同的效果。

Python 的动态类型特性允许我们有这些选择。从架构的角度思考时，没有这样的事情。在下面的例子中会变得更清楚，我们需要完全抽象依赖关系，Python 没有任何特性可以为我们做到这一点。

有些人可能会争辩说：“嗯，对象关系映射器 (ORM) 是一个很好的数据库抽象，不是吗？”不可以。ORM 本身是一个依赖项，因此不受我们控制。在 ORM 的 API 和我们的应用程序之间创建一个中间层，一个适配器会更好。

这意味着我们不会仅仅使用 ORM 来抽象数据库；我们使用我们在其上创建的抽象层来定义属于我们领域的我们自己的对象。如果这种抽象恰好在下面使用了 ORM，那是巧合；领域层（我们的业务逻辑所在）不应该关心它。

拥有我们自己的抽象为我们提供了更多的灵活性和对应用程序的控制。我们甚至可能稍后决定我们根本不需要 ORM（假设是因为我们想要更多地控制我们正在使用的数据库引擎），并且如果我们将我们的应用程序与特定的 ORM（或任何一般的库）结合起来，以后更难改变。这个想法是将我们应用程序的核心与我们无法控制的外部依赖项隔离开来。

然后应用程序导入该组件，并使用该层提供的实体，但反之则不然。抽象层不应该知道我们应用程序的逻辑；更正确的是，数据库应该对应用程序本身一无所知。如果是这种情况，数据库将与我们的应用程序耦合。目标是反转依赖——这一层提供了一个 API，每个想要连接的存储组件都必须符合这个 API。这是六边形架构 (HEX) 的概念。

在下一节中，我们将分析有助于我们创建在我们的架构中使用的组件的具体工具。

## 软件组件

我们现在有一个大型系统，我们需要扩展它。它也必须是可维护的。在这一点上，问题不仅是技术上的，而且是组织上的。这意味着它不仅仅是管理软件存储库；每个存储库很可能属于一个应用程序，并且由拥有该部分系统的团队维护。

这要求我们牢记一个大型系统如何划分为不同的组件。这可以有很多阶段，从非常简单的方法，比如创建 Python 包，到微服务架构中更复杂的场景。

当涉及不同的语言时，情况可能会更加复杂，但在本章中，我们将假设它们都是 Python 项目。

这些组件需要交互，团队也是如此。这可以大规模工作的唯一方法是如果所有部分都同意一个接口，一个合同。

### 包

Python 包是一种以更通用的方式分发软件和重用代码的便捷方式。已构建的包可以发布到工件存储库（例如公司的内部 PyPi 服务器），其他需要它们的应用程序将从那里下载它们。

这种方法背后的动机有很多元素——它是为了重用代码，同时实现概念完整性。

在这里，我们讨论打包可在存储库中发布的 Python 项目的基础知识。默认存储库可能是 PyPi（Python 包索引，位于 https://pypi.org/），也可能是内部存储库；或自定义设置将使用相同的基础知识。

我们将模拟我们创建了一个小型库，我们将以此为例来回顾要考虑的要点。

除了所有可用的开源库，有时我们可能需要一些额外的功能——也许我们的应用程序重复使用特定的习惯用法，或者非常依赖某个功能或机制，而团队已经为这些特定需求设计了更好的功能。为了更有效地工作，我们可以将这个抽象放入一个库中，并鼓励所有团队成员使用它提供的习语，因为这样做有助于避免错误并减少错误。

当您拥有一项服务和该服务的客户端库时，通常就是这种情况。您不希望客户端直接调用您的 API，因此，您可以为他们提供一个客户端库。这个库的代码将被包装到一个 Python 包中，并通过内部包管理系统分发。

可能有无数个例子可以适合这种情况。也许应用程序需要提取大量 .tar.gz 文件（以特定格式），并且过去曾面临安全问题，恶意文件以路径遍历攻击告终。

作为一种缓解措施，用于安全地抽象自定义文件格式的功能被放在一个库中，该库包装了默认格式并添加了一些额外的检查。这听起来是个好主意。

或者可能有一个配置文件需要编写，或者解析成特定格式，这需要按顺序执行许多步骤； 再次，创建一个辅助函数来包装它，并在所有需要它的项目中使用它，构成了一项很好的投资，不仅因为它节省了大量的代码重复，还因为它更难出错。

收益不仅符合 DRY 原则（避免代码重复，鼓励重用），而且抽象的功能代表了应该如何做的单一参考点，因此有助于实现概念完整性。

通常，库的最小布局如下所示：

```
├── Makefile
├── README.rst
├── setup.py
├── src
│   └── apptool
│   ├── common.py
│   ├── __init__.py
│   └── parse.py
└── tests
    ├── integration
    └── unit
```

重要的部分是 setup.py 文件，其中包含包的定义。 在此文件中，指定了项目的所有重要定义（其要求、依赖项、名称、描述等）。

src 下的 apptool 目录是我们正在处理的库的名称。 这是一个典型的 Python 项目，所以我们把我们需要的所有文件都放在这里。

setup.py 文件的示例可能是：

```python
from setuptools import find_packages, setup
with open("README.rst", "r") as longdesc:
    long_description = longdesc.read()
setup(
    name="apptool",
    description="Description of the intention of the package",
    long_description=long_description,
    author="Dev team",
    version="0.1.0",
    packages=find_packages(where="src/"),
    package_dir={"": "src"},
)
```

这个最小的例子包含项目的关键元素。 setup 函数中的 name 参数用于给出包在存储库中的名称（在这个名称下，我们运行命令来安装它；在本例中，它是 pip install apptool）。不严格要求它与项目目录的名称（src/apptool）匹配，但强烈推荐它，这样对用户来说更容易。

在这种情况下，由于两个名称匹配，因此更容易看到 pip install apptool 和然后在我们的代码中 from apptool import myutil 之间的关系。但后者对应 src/ 目录下的名称，前者对应 setup.py 文件中指定的名称。

版本对于保持不同版本的继续进行很重要，然后指定包。通过使用 find_packages() 函数，我们会自动发现包中的所有内容，在本例中位于 src/ 目录下。在此目录下搜索有助于避免混淆超出项目范围的文件，例如，意外发布测试或破坏项目结构。

一个包是通过运行以下命令构建的，假设它在安装了依赖项的虚拟环境中运行：

```python
python –m venv env
source env/bin/activate
$VIRTUAL_ENV/bin/pip install -U pip wheel
$VIRTUAL_ENV/bin/python setup.py sdist bdist_wheel
```

这会将工件放置在 dist/ 目录中，以后可以从那里将它们发布到 PyPi 或公司的内部包存储库。

打包 Python 项目的关键点是：

- 测试并验证安装是否独立于平台并且不依赖于任何本地设置（这可以通过将源文件放在 src/ 目录下来实现）。这意味着构建的包不应依赖于本地机器上的文件，并且在交付时将不可用（也不在自定义目录结构中）。
- 确保单元测试不作为正在构建的包的一部分提供。这是为了生产。在将在生产中运行的 Docker 映像中，您不需要额外的文件（例如，fixtures）不是严格需要的。
- 独立的依赖——项目严格需要运行的东西和开发者需要的东西是不一样的。
- 为最需要的命令创建入口点是个好主意。

setup.py 文件支持多个其他参数和配置，并且可能以更复杂的方式受到影响。如果我们的包需要安装多个操作系统库，最好在 setup.py 文件中编写一些逻辑来编译和构建所需的扩展。这样，如果出现问题，它会在安装过程的早期失败，如果包提供了有用的错误消息，用户将能够更快地修复依赖项并继续。

安装此类依赖项是使应用程序无处不在且易于任何开发人员（无论选择何种平台）运行的另一个困难步骤。克服这一障碍的最佳方法是通过创建 Docker 镜像来抽象平台，我们将在下一节中讨论。

#### 管理依赖

在描述我们将如何利用 Docker 容器来交付我们的应用程序之前，先看看软件配置管理 (SCM) 问题很重要，即：我们如何列出应用程序的依赖项，以便它们是可重复的？

请记住，软件中的问题可能不仅来自我们的代码。外部依赖也会影响最终交付。在任何时候，您都想知道已交付的软件包及其版本的完整列表。这称为基线。

这个想法是，如果依赖项在任何时候给我们的软件带来了问题，您都希望能够快速查明它。更重要的是，你还希望你的构建是可重复的：假设其他一切都没有改变，一个新的构建应该产生与上一个完全相同的工件。

该软件通过遵循开发流程交付到生产环境中。这从第一个环境开始，然后在其上运行测试（集成、验收等），然后通过持续集成和持续部署，它会通过管道的不同阶段（例如，如果您有一个测试版） - 测试环境，或在最终达到生产之前的预生产）。

Docker 非常擅长确保沿管道移动完全相同的图像，但不能保证如果您再次通过管道运行相同版本的代码（例如相同的 git commit），您将获得相同的结果.这项工作由我们负责，这也是我们在本节中探索的内容。

假设我们的 web 包的 setup.py 文件如下所示：

```python
from setuptools import find_packages, setup
 
with open("README.rst", "r") as longdesc:
    long_description = longdesc.read()
install_requires = ["sanic>=20,<21"]
setup(
    name="web",
    description="Library with helpers for the web-related functionality",
    long_description=long_description,
    author="Dev team",
    version="0.1.0",
    packages=find_packages(where="src/"),
    package_dir={"": "src"},
    install_requires=install_requires,
)
```

在这种情况下，只有一个依赖项（在 install_requires 参数中声明），并且它控制着一个版本间隔。这通常是一个很好的做法：我们希望至少使用一个包的特定版本，但我们也有兴趣不要超越下一个主要版本（因为主要版本可以进行向后不兼容的更改）。

我们像这样设置版本是因为我们有兴趣获取依赖项的更新（有像 Dependabot 这样的工具——https://dependabot.com/——可以自动检测我们的依赖项何时有新版本，并且可以打开一个新的 pull request），但我们仍然想知道在任何给定时间安装的确切版本。

不仅如此，我们还希望跟踪完整的依赖关系树，这意味着还应该列出传递依赖关系。

一种方法是使用 pip-tools (https://github.com/jazzband/pip-tools) 并编译 requirements.txt 文件。

想法是使用此工具从 setup.py 文件生成需求文件，如下所示：

```python
pip-compile setup.py
```

这将生成一个 requirements.txt 文件，我们将在 Dockerfile 中使用该文件来安装依赖项。

> 始终从 requirements.txt 文件安装 Dockerfile 中的依赖项，以便从版本控制的角度来看具有确定性的构建。

列出需求的文件应该置于版本控制之下，每当我们想要升级依赖项时，我们都会再次运行带有 –U 标志的命令并跟踪需求文件的新版本。

列出所有依赖项不仅有利于可重复性，而且还增加了清晰度。如果您使用许多依赖项，则可能会发生与版本冲突的情况，如果我们知道哪个包导入了哪个库（以及哪个版本），这将更容易发现。但同样，这只是问题的一部分。在处理依赖项时，我们需要考虑更多因素。

#### 管理依赖项时的其他注意事项

默认情况下，安装依赖项时，pip 将使用来自 Internet (https://pypi.org/) 的公共存储库。也可以从其他索引，甚至版本控制系统进行安装。

这有一些问题和局限性。首先，您将取决于这些服务的可用性。还有一个警告，您将无法在公共存储库上发布您的内部包（其中包含您公司的知识产权）。最后，还有一个问题是我们真的不确定某些作者在保持工件版本准确和安全方面的可靠性或可信度（例如，一些作者可能想要重新发布不同版本的具有相同版本号的代码，这显然是错误且不允许的，但所有系统都有缺陷）。我不记得在 Python 中出现过这样的特定问题，但我确实记得几年前这发生在 JavaScript 社区，当时有人从 NPM 注册表 (REGISTER01) 中删除了一个包，并且通过取消发布这个库，许多其他构建坏了。即使 PyPi 不允许这样做，我们也不希望任由其他人的善（或恶）信摆布。

解决方案很简单：您的公司必须有一个用于依赖的内部服务器，并且所有构建都必须针对这个内部存储库。无论这是如何实现的（在本地、在云上、通过使用开源工具或通过外包给提供商），想法都是必须将新的、需要的依赖项添加到此存储库中，这也是内部包也在其中发布。

确保此内部存储库得到更新并配置所有存储库以在您的依赖项的新版本可用时接收升级。请记住，这也是另一种形式的技术债务。有几个原因。正如我们在前几章中讨论的那样，技术债务不仅仅是编写糟糕的代码。当新技术可用时，您会错过这些功能，这意味着您可能会更好地利用可用技术。更重要的是，随着时间的推移，软件包可能存在安全漏洞，因此您需要升级以确保您的软件已打补丁。

> 拥有过时版本的依赖项是另一种形式的技术债务。养成使用最新版本的依赖项的习惯。

在升级依赖项之前不要让太多时间过去，因为您等待的越多，就越难赶上。毕竟，这就是持续集成的重点：您希望以增量方式持续集成更改（包括新的依赖项），前提是您有自动化测试作为构建的一部分运行并充当回归的安全网.

> 配置一个工具，自动发送新版本依赖项的拉取请求，并配置对它们的自动安全检查。

此工作流程应该需要最少的工作。这个想法是你用一系列版本配置项目的 setup.py 文件并拥有需求文件。当有新版本可用时，您为存储库配置的工具将重建需求文件，该文件将列出所有包及其新版本（这将显示在工具打开的拉取请求的差异中）。如果构建是绿色的，并且拉取请求显示的差异没有任何可疑之处，您可以继续合并，相信持续集成会发现问题。另一方面，如果构建失败，则需要您的干预进行调整。

#### 人为版本

稳定性和尖端软件之间存在权衡。拥有最新版本通常是积极的，因为这意味着我们只需升级即可获得最新的功能和错误修复。那时新版本不会带来不兼容的更改（缺点）。因此，软件以具有明确含义的版本进行管理。

当我们建立一系列所需的版本时，我们希望获得升级，但同时不要太激进而破坏应用程序。

如果我们只升级依赖项并编写新版本的需求文件，我们应该发布我们工件的新版本（毕竟，我们正在交付一些新的东西，因此不同）。这可以是小版本或微型版本，但重要的是，当我们发布自己的自定义工件时，我们必须遵守与第三方库相同的规则。

在 Python 中对此的一个很好的参考是 PEP-440 (https://www.python.org/dev/peps/pep-0440/)，它描述了如何在 setup.py 文件中为我们的库设置版本号。

在下一节中，我们将了解一种不同的技术，它也将帮助我们创建组件来交付我们的代码。

### Docker 容器

本章专门介绍架构，因此术语容器指的是与 Python 容器（具有 __contains__ 方法的对象）完全不同的东西，在第 2 章 Pythonic 代码中进行了探讨。容器是运行在操作系统下的一个进程，有一定的限制和隔离考虑。具体来说，我们指的是 Docker 容器，它允许将应用程序（服务或进程）作为独立的组件进行管理。

容器代表了另一种交付软件的方式。创建考虑到上一节中的注意事项的 Python 包更适合库或框架，其目标是重用代码并利用使用收集特定逻辑的单一位置。

在容器的情况下，目标不是创建库而是应用程序（大部分时间）。但是，应用程序或平台并不一定意味着整个服务。构建容器的想法是创建小组件来代表具有小而明确目的的服务。

在本节中，我们将在谈论容器时提及 Docker，我们将探索如何为 Python 项目创建 Docker 镜像和容器的基础知识。请记住，这不是将应用程序启动到容器中的唯一技术，而且它完全独立于 Python。

一个 Docker 容器需要一个镜像来运行，这个镜像是从其他基础镜像创建的。但是我们创建的镜像本身可以作为其他容器的基础镜像。如果我们的应用程序中有一个可以跨多个容器共享的公共基础，我们将希望这样做。一个潜在的用途是创建一个基本映像，以我们在上一节中描述的方式安装一个（或多个）包，以及它的所有依赖项，包括操作系统级别的依赖项。如第 9 章“通用设计模式”所述，我们创建的包不仅可以依赖于其他 Python 库，还可以依赖于特定平台（特定操作系统）以及预装在该操作系统中的特定库，否则包将根本不安装，会失败。

为此，容器是一个很好的可移植性工具。它们可以帮助我们确保我们的应用程序具有规范的运行方式，并且它们还将大大简化开发过程（跨环境重现场景、复制测试、新团队成员入职等）。

Docker 有助于避免平台相关问题。这个想法是我们将 Python 应用程序打包为 Docker 容器映像，这对于在本地开发和测试以及在生产中启动我们的软件非常有用。

通常，在过去，Python 由于其性质而难以部署。由于它是一种解释型语言，您编写的代码将由生产环境中主机上的 Python 虚拟机运行。因此，您需要确保目标平台具有您期望的解释器版本。此外，依赖项的打包也很困难：这是通过将所有内容打包到虚拟环境中并运行它来完成的。如果您有依赖于平台的细节，并且您的某些依赖项使用 C 扩展，事情就会变得更加困难。在这里，我什至不是在谈论 Windows 或 Linux；有时，即使是不同版本的 Linux（基于 Debian 与基于 Red Hat）也有不同版本的代码运行所需的 C 库，因此测试应用程序并确保其正常运行的唯一真正方法是使用虚拟机，并根据正确的架构编译所有内容。在现代应用程序中，大多数这些痛苦都应该消失。现在，您的根目录中将有一个 Dockerfile，其中包含构建该应用程序的说明。您的应用程序也可以通过在 Docker 中运行来交付生产。

正如包是我们重用代码和统一标准的方式一样，容器代表了我们创建应用程序不同服务的方式。它们符合架构的关注点分离 (SoC) 原则背后的标准。每个服务都是另一种组件，它将独立于应用程序的其余部分封装一组功能。这些容器的设计方式应该有利于可维护性——如果职责明确划分，服务的更改不应影响应用程序的任何其他部分。

我们将在下一节介绍如何从 Python 项目创建 Docker 容器的基础知识。

### 用例

作为我们如何组织应用程序组件以及先前概念在实践中如何工作的示例，我们提供以下简单示例。

用例是有一个交付食物的应用程序，该应用程序有一个特定的服务，用于跟踪每个交付在不同阶段的状态。我们将只关注此特定服务，而不管应用程序的其余部分如何显示。该服务必须非常简单——一个 REST API，当被问及特定订单的状态时，它将返回一个带有描述性消息的 JSON 响应。

我们将假设有关每个特定订单的信息存储在数据库中，但此细节根本无关紧要。

我们的服务目前有两个主要关注点：获取有关特定订单的信息（从可能存储的任何位置），并以有用的方式向客户呈现此信息（在这种情况下，以 JSON 格式提供结果，公开为网络服务）。

由于应用程序必须是可维护和可扩展的，我们希望尽可能隐藏这两个关注点并专注于主要逻辑。因此，将这两个细节抽象并封装到具有核心逻辑的主应用程序将使用的Python包中，如图10.1所示：

![使用两个 Python 包的服务应用程序（名为“Web 服务”），其中一个连接到数据库](./img/10-1.png)

在下面的部分中，我们简要演示代码可能如何出现，主要是包，以及如何从这些包创建服务，以便最终看到我们可以推断出什么结论。

#### 编码

在这个例子中创建 Python 包的想法是为了说明如何制作抽象和隔离的组件，以便有效地工作。实际上，这些实际上并不需要是 Python 包；我们可以创建正确的抽象作为“交付服务”项目的一部分，并且在保留正确隔离的同时，它将毫无问题地工作。

当存在将要重复的逻辑并且预计将在许多其他应用程序（将从这些包中导入）中使用的逻辑时，创建包更有意义，因为我们希望支持代码重用。在这种特殊情况下，没有这样的要求，所以它可能超出了设计的范围，但这种区别仍然使“可插拔架构”或组件的概念更加清晰，这实际上是我们不知道的抽象技术细节的包装器不是很想对付，更不用说依赖了。

存储包负责检索所需的数据，并以适合业务规则的方便格式将其呈现给下一层（交付服务）。主应用程序现在应该知道这些数据来自哪里，它的格式是什么，等等。这就是我们在两者之间进行这种抽象的全部原因，因此应用程序不直接使用行或 ORM 实体，而是使用一些可行的方法。

#### 领域模型

以下定义适用于业务规则的类。请注意，它们是纯业务对象，不与任何特定对象绑定。它们不是 ORM 的模型，也不是外部框架的对象，等等。应用程序应该使用这些对象（或具有相同条件的对象）。

在每种情况下，文档字符串都根据业务规则记录了每个类的用途：

```python
from typing import Union
class DispatchedOrder:
    """An order that was just created and notified to start its delivery."""
    status = "dispatched"
    def __init__(self, when):
        self._when = when
    def message(self) -> dict:
        return {
            "status": self.status,
            "msg": "Order was dispatched on {0}".format(
                self._when.isoformat()
            ),
        }
class OrderInTransit:
    """An order that is currently being sent to the customer."""
    status = "in transit"
    def __init__(self, current_location):
        self._current_location = current_location
    def message(self) -> dict:
        return {
            "status": self.status,
            "msg": "The order is in progress (current location: {})".format(
                self._current_location
            ),
        }
class OrderDelivered:
    """An order that was already delivered to the customer."""
    status = "delivered"
    def __init__(self, delivered_at):
        self._delivered_at = delivered_at
    def message(self) -> dict:
        return {
            "status": self.status,
            "msg": "Order delivered on {0}".format(
                self._delivered_at.isoformat()
            ),
        }
class DeliveryOrder:
    def __init__(
        self,
        delivery_id: str,
        status: Union[DispatchedOrder, OrderInTransit, OrderDelivered],
    ) -> None:
        self._delivery_id = delivery_id
        self._status = status
    def message(self) -> dict:
        return {"id": self._delivery_id, **self._status.message()}
```

从这段代码中，我们已经可以了解应用程序的样子——我们想要一个 DeliveryOrder 对象，它有自己的状态（作为内部合作者），一旦我们有了状态，我们将调用它的消息 () 方法将此信息返回给用户。

#### 从应用程序调用

这就是这些对象将如何在应用程序中使用的方式。 请注意这如何取决于以前的包（网络和存储），而不是相反：

```python
from storage import DBClient, DeliveryStatusQuery, OrderNotFoundError
from web import NotFound, View, app, register_route
class DeliveryView(View):
    async def _get(self, request, delivery_id: int):
        dsq = DeliveryStatusQuery(int(delivery_id), await DBClient())
        try:
            result = await dsq.get()
        except OrderNotFoundError as e:
             raise NotFound(str(e)) from e
        return result.message()
register_route(DeliveryView, "/status/<delivery_id:int>")
```

在上一节中，显示了域对象，这里显示了应用程序的代码。我们是不是错过了什么？当然，但我们现在真的需要知道吗？不必要。

storage 和 web 包中的代码被故意省略了（尽管读者被鼓励去看它——这本书的存储库包含了完整的例子）。此外，这是故意这样做的，选择此类包的名称是为了不透露任何技术细节——存储和网络。

再次查看前面清单中的代码。你能说出正在使用哪些框架吗？它是否说明数据是来自文本文件、数据库（如果是，是什么类型？SQL？NoSQL？）还是其他服务（例如网络）？假设它来自关系数据库。是否有任何关于如何检索这些信息的线索（手动 SQL 查询？通过 ORM？）？

网络呢？我们能猜出使用了哪些框架吗？

我们无法回答这些问题中的任何一个这一事实可能是一个好兆头。这些都是细节，细节应该被封装。我们无法回答这些问题，除非我们查看这些包中的内容。

还有另一种回答前面问题的方法，它以问题本身的形式出现：我们为什么需要知道那个？查看代码，我们可以看到有一个 DeliveryOrder，使用交付的标识符创建，并且它有一个 get() 方法，该方法返回一个表示交付状态的对象。如果所有这些信息都是正确的，那就是我们应该关心的全部内容。它的完成方式有何不同？

我们创建的抽象使我们的代码具有声明性。在声明式编程中，我们声明了我们想要解决的问题，而不是我们想要如何解决它。它与命令式相反，在命令式中，我们必须使所有需要的步骤都明确以获取某些东西（例如，连接到数据库、运行此查询、解析结果、将其加载到此对象中，等等）。在这种情况下，我们声明我们只想知道某个标识符给出的交付状态。

这些包负责处理细节并以方便的格式呈现应用程序所需的内容，即上一节中介绍的那种对象。我们只需要知道存储包包含一个对象，给定一个交付的 ID 和一个存储客户端（为了简单起见，这个依赖项被注入到这个例子中，但其他替代方案也是可能的），它将检索 DeliveryOrder，这然后我们可以要求撰写消息。

这种架构提供了便利，并且更容易适应变化，因为它保护业务逻辑的内核免受可能发生变化的外部因素的影响。

想象一下，我们想要改变信息的检索方式。 那会有多难？ 该应用程序依赖于一个 API，如下所示：

```python
dsq = DeliveryStatusQuery(int(delivery_id), await DBClient())
```

因此，这只是改变 get() 方法的工作方式，使其适应新的实现细节。我们所需要的只是让这个新对象在其 get() 方法上返回 DeliveryOrder ，这就是全部。我们可以更改查询、ORM、数据库等，而且，在所有情况下，应用程序中的代码都不需要更改！

### 适配器
尽管如此，无需查看包中的代码，我们可以得出结论，它们可以作为应用程序技术细节的接口。

实际上，由于我们是从高层的角度看应用程序，不需要看代码，我们可以想象在那些包里面一定有适配器设计模式的实现（在第9章，通用设计模式中介绍） ）。这些对象中的一个或多个正在使外部实现适应应用程序定义的 API。这样，想要与应用程序一起工作的依赖项必须符合 API，并且必须制作一个适配器。

不过，在应用程序的代码中有一条与此适配器有关的线索。注意视图是如何构建的。它继承自一个名为 View 的类，该类来自我们的 web 包。我们可以推断，这个 View 是从可能正在使用的 Web 框架之一派生的类，它通过继承创建了一个适配器。需要注意的重要一点是，一旦完成，唯一重要的对象就是我们的 View 类，因为在某种程度上，我们正在创建自己的框架，该框架基于对现有框架的调整（但同样，更改框架将意味着只更改适配器，而不是整个应用程序）。

从下一节开始，我们将看看这些服务的内部是什么样的。

## 服务

为了创建服务，我们将在 Docker 容器中启动 Python 应用程序。从基础镜像开始，容器必须安装要运行的应用程序的依赖项，该应用程序还具有操作系统级别的依赖项。

这实际上是一种选择，因为它取决于如何使用依赖项。如果我们使用的软件包在安装时需要操作系统上的其他库进行编译，我们可以通过为我们的库平台构建一个轮子并直接安装它来避免这种情况。如果在运行时需要这些库，则别无选择，只能将它们作为容器映像的一部分。

现在，我们将讨论准备在 Docker 容器内运行的 Python 应用程序的众多方法之一。这是将 Python 项目打包到容器中的众多替代方法之一。首先，我们来看看目录的结构是什么样的：

```
├── Dockerfile
├── libs
│   ├── README.rst
│   ├── storage
│   └── web
├── Makefile
├── README.rst
├── setup.py
└── statusweb
    ├── __init__.py
    └── service.py
```

libs 目录可以被忽略，因为它只是放置依赖项的地方（显示在这里是为了在 setup.py 文件中引用它们时记住它们，但它们可以放置在不同的存储库中并通过 pip 远程安装）。

我们有带有一些帮助命令的 Makefile，然后是 setup.py 文件，以及 statusweb 目录中的应用程序本身。打包应用程序和库之间的一个常见区别是，后者在 setup.py 文件中指定了它们的依赖项，而前者有一个 requirements.txt 文件，通过 pip install -r requirements.txt 安装依赖项。通常，我们会在 Dockerfile 中执行此操作，但为了使事情更简单，在此特定示例中，我们假设从 setup.py 文件中获取依赖项就足够了。这是因为除了这个考虑之外，在处理依赖的时候还有很多需要考虑的问题，比如冻结包的版本，跟踪间接依赖，使用pipenv等额外的工具，以及更多的话题章的范围。此外，为了一致性，还习惯于从 requirements.txt 读取 setup.py 文件。

现在我们有了 setup.py 文件的内容，其中说明了应用程序的一些细节：

```python
from setuptools import find_packages, setup
with open("README.rst", "r") as longdesc:
    long_description = longdesc.read()
install_requires = ["web==0.1.0", "storage==0.1.0"]
setup(
    name="delistatus",
    description="Check the status of a delivery order",
    long_description=long_description,
    author="Dev team",
    version="0.1.0",
    packages=find_packages(),
    install_requires=install_requires,
    entry_points={
        "console_scripts": [
            "status-service = statusweb.service:main",
        ],
    },
)
```

我们注意到的第一件事是应用程序声明了它的依赖项，这些依赖项是我们创建并放置在 libs/ 下的包，即 web 和存储，抽象和适配一些外部组件。反过来，这些包将具有依赖项，因此我们必须确保容器在创建映像时安装所有必需的库，以便它们可以成功安装，然后再安装此包。

我们注意到的第二件事是传递给 setup 函数的 entry_points 关键字参数的定义。这不是严格强制性的，但创建一个入口点是个好主意。当软件包安装在虚拟环境中时，它会共享此目录及其所有依赖项。虚拟环境是具有给定项目依赖项的目录结构。它有许多子目录，但最重要的是：

- <virtual-env-root>/lib/<python-version>/site-packages
- <virtual-env-root>/bin

第一个包含安装在该虚拟环境中的所有库。如果我们要为这个项目创建一个虚拟环境，该目录将包含 web 和存储包，以及它的所有依赖项，以及一些额外的基本依赖项和当前项目本身。

第二个 /bin/ 包含当该虚拟环境处于活动状态时可用的二进制文件和命令。默认情况下，它只是 Python、pip 和其他一些基本命令的版本。当我们创建一个控制台入口点时，具有该声明名称的二进制文件被放置在那里，因此，当环境处于活动状态时，我们可以运行该命令。调用此命令时，它将运行在虚拟环境的所有上下文中指定的函数。这意味着它是一个我们可以直接调用的二进制文件，而不必担心虚拟环境是否处于活动状态，或者依赖项是否安装在当前运行的路径中。

定义如下：

```
"status-service = statusweb.service:main"
```

等号的左侧声明入口点的名称。 在这种情况下，我们将有一个名为 status-service 的命令可用。 右侧声明了该命令应该如何运行。 它需要定义函数的包，后跟 : 后的函数名。 在这种情况下，它将运行在 statusweb/service.py 中声明的主函数。

接下来是 Dockerfile 的定义：

```dockerfile
FROM python:3.9-slim-buster
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
        python-dev \
        gcc \
        musl-dev \
        make \
    && rm -rf /var/lib/apt/lists/*
WORKDIR /app
ADD . /app
RUN pip install /app/libs/web /app/libs/storage
RUN pip install /app
EXPOSE 8080
CMD ["/usr/local/bin/status-service"]
```

该镜像基于安装了 Python 的轻量级 Linux 镜像构建，然后安装操作系统依赖项，以便可以部署我们的库。 按照前面的考虑，这个 Dockerfile 只是简单地复制了库，但这也可以相应地从 requirements.txt 文件安装。 在所有 pip install 命令准备就绪后，它会复制工作目录中的应用程序，来自 Docker 的入口点（CMD 命令，不要与 Python 混淆）调用我们放置函数的包的入口点 启动进程。 对于本地开发，我们仍然会使用 Dockerfile，以及 docker-compose.yml 文件，其中包含所有服务（包括依赖项，如数据库）、基础映像以及它们如何链接和互连的定义。

现在我们已经运行了容器，我们可以启动它并对其运行一个小测试以了解它是如何工作的：

```bash
$ curl http://localhost:5000/status/1
{"id":1,"status":"dispatched","msg":"Order was dispatched on 2018-08-01T22:25:12+00:00"}
```

让我们从下一节开始分析迄今为止所见代码的架构特征。

#### 分析

从之前的实现中可以得出很多结论。虽然这似乎是一个好方法，但也有好处。毕竟，没有任何架构或实现是完美的。这意味着像这样的解决方案不可能适用于所有情况，因此它在很大程度上取决于项目、团队、组织等的情况。

虽然解决方案的主要思想是尽可能多地抽象细节，但正如我们将看到的，有些部分不能完全抽象掉，层之间的契约也意味着抽象泄漏。

毕竟，技术总是在悄悄涌现。例如，如果我们要将我们的实现从 REST 服务更改为通过 GraphQL 为我们的数据提供服务，我们将不得不调整应用服务器的配置和构建方式，但是，我们仍然应该能够具有与前一个非常相似的结构。即使我们想要进行更彻底的改变，将我们的服务转变为 gRPC 服务器，我们当然会被迫调整一些胶水代码，但我们仍然应该能够尽可能多地使用我们的包。所需的更改应保持在最低限度。

#### 依赖流

请注意，当依赖关系靠近业务规则所在的内核时，依赖项仅向一个方向流动。这可以通过查看导入语句来追踪。例如，该应用程序从存储中导入它需要的所有内容，而且这绝不是颠倒的。

打破这个规则会产生耦合。现在代码的排列方式意味着应用程序和存储之间存在弱依赖关系。 API 是这样的，我们需要一个带有 get() 方法的对象，并且任何想要连接到应用程序的存储都需要根据这个规范来实现这个对象。因此，依赖关系是倒置的——由每个存储来实现这个接口，以便根据应用程序的期望创建一个对象。

#### 限制

并非一切都可以抽象出来。在某些情况下，这是不可能的，而在其他情况下，它可能不方便。让我们从便利方面开始。

在这个例子中，有一个选择的 web 框架的适配器到一个干净的 API 来呈现给应用程序。在更复杂的场景中，这样的更改可能是不可能的。即使有了这种抽象，应用程序仍然可以看到部分库。与 Web 框架完全隔离并不完全是一个问题，因为迟早我们会需要它的一些功能或技术细节。

这里的重要收获不是适配器，而是尽可能隐藏技术细节的想法。这意味着在应用程序代码清单上显示的最好的事情不是我们的 Web 框架版本和实际版本之间存在适配器这一事实，而是没有提及后者这一事实在可见代码的任何部分按名称。该服务已明确表示 web 只是一个依赖项（正在导入的一个细节），并揭示了它应该做什么背后的意图。目标是揭示意图（如代码中所示）并尽可能推迟细节。

至于哪些东西不能被隔离，那就是那些最接近代码的元素。在这种情况下，Web 应用程序以异步方式使用在其中运行的对象。这是我们无法规避的硬约束。确实，存储包中的任何内容都可以更改、重构和修改，但是无论这些修改是什么，它仍然需要保留接口，包括异步接口。

#### 可测试性

同样，与代码非常相似，体系结构可以从将部分分成更小的组件中受益。依赖项现在由单独的组件隔离和控制的事实使我们对主应用程序进行了更清晰的设计，现在更容易忽略边界以专注于测试应用程序的核心。

例如，我们可以为依赖项创建补丁并编写更简单的单元测试（它们不需要数据库），或者启动整个 Web 服务。使用纯域对象意味着更容易理解代码和单元测试。即使是适配器也不需要那么多测试，因为它们的逻辑应该非常简单。

请记住第 8 章单元测试和重构中提到的软件测试金字塔。我们希望有大量的单元测试，然后是更少的组件测试，最后是更少的集成测试。将我们的架构分成不同的组件对组件测试大有帮助：我们可以模拟我们的依赖关系并隔离测试一些组件。

这既便宜又快捷，但这并不意味着我们根本不应该进行集成测试。为了确保我们的最终应用程序按预期工作，我们需要集成测试来测试我们架构的所有组件（微服务或包），协同工作。

意图揭示
意图揭示是我们代码的一个关键概念——每个名字都必须明智地选择，清楚地传达它应该做什么。每个功能都应该讲述一个故事。我们应该保持函数简短、关注点分离、依赖隔离，并为代码的每个部分中的抽象分配正确的含义。

好的架构应该揭示它所包含的系统的意图。它不应该提及它所使用的工具；这些都是细节，正如我们详细讨论的那样，细节应该隐藏和封装。

## 总结

优秀软件设计的原则适用于所有级别。与我们想要编写可读代码的方式相同，为此我们需要牢记代码的意图揭示方面，架构也必须表达它试图解决的问题的意图。

所有这些想法都是相互关联的。同样的意图揭示确保我们的架构是根据域问题定义的，也使我们尽可能地抽象细节，创建抽象层，反转依赖关系，并分离关注点。

在重用代码方面，Python 包是一个很好且灵活的选择。在决定创建包时，诸如凝聚力和单一职责原则之类的标准是最重要的考虑因素。与具有内聚性和少量职责的组件相一致，微服务的概念开始发挥作用，为此，我们已经看到了如何从打包的 Python 应用程序开始在 Docker 容器中部署服务。

与软件工程中的所有事情一样，有限制也有例外。不可能总是像我们想要的那样抽象事物或完全隔离依赖关系。有时，遵守本书中解释的原则是不可能的（或不切实际的）。但这可能是读者应该从书中得到的最好建议——它们只是原则，而不是法律。如果从框架中抽象出来是不可能的或不切实际的，那应该不是问题。请记住整本书都引用了 Python 之禅本身的内容——实用性胜过纯粹性。

## 参考

以下是您可以参考的信息列表：

- SCREAM：尖叫架构（https://8thlight.com/blog/uncle-bob/2011/09/30/Screaming-Architecture.html）
- CLEAN-01：清洁架构（https://8thlight.com/blog/uncle-bob/2012/08/13/the-clean-architecture.html）
- HEX：六边形架构 (https://staging.cockburn.us/hexagonal-architecture/)
- PEP-508：Python 软件包的依赖规范 (https://www.python.org/dev/peps/pep-0508/)
- 在 Python 中打包和分发项目：https://python-packaging-user-guide.readthedocs.io/guides/distributing-packages-using-setuptools/#distributing-packages
- PEP-440：https://www.python.org/dev/peps/pep-0440/
- REGISTER01：https://www.theregister.com/2016/03/23/npm_left_pad_chaos/
- Python 打包用户指南：https://packaging.python.org/
- AWS 构建器库：通过持续交付加快速度 (https://aws.amazon.com/builders-library/going-faster-with-continuous-delivery/)

## 总结一下

本书的内容是参考，是按照上述标准实施软件解决方案的一种可能方式。这些标准通过示例进行解释，并介绍了每个决定的基本原理。读者很可能不同意示例中采用的方法。

事实上，我鼓励你不同意：观点越多，辩论就越丰富。但不管意见如何，重要的是要明确这里所呈现的内容绝不是一个强有力的指令，必须严格遵守。恰恰相反;这是一种提出解决方案和一系列想法的方式，您可能会发现它们很有帮助。

正如开头所介绍的那样，本书的目标不是为您提供可以直接应用的食谱或公式，而是培养您的批判性思维。习语和语法特性来来去去；它们会随着时间而改变。但想法和核心软件概念仍然存在。使用这些工具和提供的示例，您应该更好地理解干净代码的含义。

我真诚地希望这本书能帮助你成为比你开始之前更好的开发人员，并祝你在你的项目中取得成功。

> 分享您的经验
>
> 感谢您花时间阅读本书。如果您喜欢这本书，请帮助其他人找到它。留下评论：https://www.amazon.com/dp/1800560214