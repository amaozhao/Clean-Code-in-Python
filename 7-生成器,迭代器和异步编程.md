生成器是使 Python 成为一种比更传统的语言更特殊的语言的另一个特性。在本章中，我们将探讨它们的基本原理、语言中引入它们的原因以及它们解决的问题。我们还将介绍如何使用生成器以惯用方式解决问题，以及如何使我们的生成器（或任何可迭代的，就此而言）Pythonic。

我们将理解为什么语言中自动支持迭代（以迭代器模式的形式）。从那里开始，我们将进行另一次旅程，探索生成器如何成为 Python 的一个基本特性，以支持其他功能，例如协程和异步编程。

本章的目标如下：

- 创建提高我们程序性能的生成器
- 研究迭代器（尤其是迭代器模式）如何深入嵌入 Python 中
- 惯用地解决涉及迭代的问题
- 了解生成器如何作为协同程序和异步编程的基础工作
- 探索对协程的语法支持——yield from、await 和 async def

掌握生成器将使您在编写惯用的 Python 方面走得更远，因此它们对本书很重要。在本章中，我们不仅研究了如何使用生成器，而且还探索了它们的内部结构，以深入了解它们的工作原理。

## 技术要求

本章中的示例适用于任何平台上的任何版本的 Python 3.9。

本章使用的代码可以在 https://github.com/PacktPublishing/Clean-Code-in-Python-Second-Edition 找到。说明在 README 文件中可用。

## 创建生成器

很久以前 (PEP-255) 就在 Python 中引入了生成器，其想法是在 Python 中引入迭代，同时提高程序的性能（通过使用更少的内存）。

生成器的想法是创建一个可迭代的对象，并且在它被迭代时，将一次一个地产生它包含的元素。生成器的主要用途是节省内存——而不是在内存中拥有一个非常大的元素列表，一次保存所有内容，我们有一个对象，它知道如何根据需要一次一个地生成每个特定元素。

此功能支持对内存中的重量级对象进行延迟计算，其方式与其他函数式编程语言（例如 Haskell）提供的方式类似。甚至可以使用无限序列，因为生成器的惰性特性支持这种选择。

### 第一眼看生成器

让我们从一个例子开始。现在的问题是我们想要处理大量记录并获取一些指标和指标。给定一个包含购买信息的大型数据集，我们希望对其进行处理以获得最低销售额、最高销售额和平均销售价格。

为简单起见，我们假设一个 CSV 文件只有两个字段，格式如下：

```python
<purchase_date>, <price>
...
```

我们将创建一个接收所有购买的对象，这将为我们提供必要的指标。 我们可以通过简单地使用 min() 和 max() 内置函数来获取这些值中的一些，但这需要多次迭代所有购买，因此，我们使用我们的自定义对象， 这将在一次迭代中获得这些值。

为我们获取数字的代码看起来相当简单。 它只是一个对象，其方法可以一次性处理所有价格，并且在每一步都会更新我们感兴趣的每个特定指标的值。首先，我们将在以下清单中展示第一个实现，以及 ，在本章后面（一旦我们了解了更多关于迭代的内容），我们将重新审视这个实现并获得一个更好（更紧凑）的版本。 目前，我们正在解决以下问题：

```python
class PurchasesStats:
    def __init__(self, purchases):
        self.purchases = iter(purchases)
        self.min_price: float = None
        self.max_price: float = None
        self._total_purchases_price: float = 0.0
        self._total_purchases = 0
        self._initialize()
    def _initialize(self):
        try:
            first_value = next(self.purchases)
        except StopIteration:
            raise ValueError("no values provided")
        self.min_price = self.max_price = first_value
        self._update_avg(first_value)
    def process(self):
        for purchase_value in self.purchases:
            self._update_min(purchase_value)
            self._update_max(purchase_value)
            self._update_avg(purchase_value)
        return self
    def _update_min(self, new_value: float):
        if new_value < self.min_price:
            self.min_price = new_value
    def _update_max(self, new_value: float):
        if new_value > self.max_price:
            self.max_price = new_value
    @property
    def avg_price(self):
        return self._total_purchases_price / self._total_purchases
    def _update_avg(self, new_value: float):
        self._total_purchases_price += new_value
        self._total_purchases += 1
    def __str__(self):
        return (
            f"{self.__class__.__name__}({self.min_price}, "
            f"{self.max_price}, {self.avg_price})"
        )
```

此对象将接收所有采购总额并处理所需的值。 现在，我们需要一个函数将这些数字加载到该对象可以处理的内容中。 这是第一个版本：

```python
def _load_purchases(filename):
    purchases = []
    with open(filename) as f:
        for line in f:
            *_, price_raw = line.partition(",")
            purchases.append(float(price_raw))
    return purchases
```

此代码有效； 它将文件的所有数字加载到一个列表中，当传递给我们的自定义对象时，将生成我们想要的数字。 不过，它有一个性能问题。 如果您使用相当大的数据集运行它，它将需要一段时间才能完成，如果数据集大到无法放入主内存，它甚至可能会失败。

如果我们查看使用这些数据的代码，它一次一个地处理购买，所以我们可能想知道为什么我们的生产者一次将所有内容都放入内存中。 它正在创建一个列表，其中包含文件的所有内容，但我们知道我们可以做得更好。

解决方案是创建一个生成器。 我们将一次生成一个结果，而不是将文件的全部内容加载到列表中。 代码现在看起来像这样：

```python
def load_purchases(filename):
    with open(filename) as f:
        for line in f:
            *_, price_raw = line.partition(",")
            yield float(price_raw)
```

如果你测量这次的进程，你会发现内存的使用量已经明显下降了。 我们还可以看到代码看起来更简单了——不需要定义列表（因此不需要追加），返回语句也消失了。

在这种情况下，load_purchases 函数是一个生成器函数，或者只是一个生成器。

在 Python 中，任何函数中仅存在关键字 yield 就使其成为生成器，因此，在调用它时，除了创建生成器的实例之外什么都不会发生：

```python
>>> load_purchases("file")
<generator object load_purchases at 0x...>
```

生成器对象是一个可迭代对象（稍后我们将更详细地重新讨论可迭代对象），这意味着它可以与 for 循环一起使用。请注意，我们无需对消费者代码进行任何更改——在新实现之后，我们的统计处理器保持不变，for 循环未修改。

使用 iterables 允许我们创建这些类型的强大抽象，这些抽象对于 for 循环来说是多态的。只要我们保持可迭代接口，我们就可以透明地迭代该对象。

我们在本章中探索的是另一种与 Python 本身完美融合的惯用代码案例。在前面的章节中，我们已经看到了如何实现我们自己的上下文管理器来将我们的对象连接到 with 语句，或者我们如何创建自定义容器对象来利用 in 运算符或 if 语句的布尔值，等等。现在轮到 for 运算符了，为此，我们将创建迭代器。

在深入了解生成器的细节和细微差别之前，我们可以快速了解一下生成器如何与我们已经看到的一个概念相关联：理解。推导式形式的生成器称为生成器表达式，我们将在下一节中简要讨论它。

### 生成器表达式

生成器可以节省大量内存，而且由于它们是迭代器，因此它们是其他需要更多内存空间的可迭代对象或容器（例如列表、元组或集合）的便捷替代方案。

就像这些数据结构一样，它们也可以通过推导式定义，只是它们被称为生成器表达式（关于它们是否应该称为生成器推导式一直存在争论。在本书中，我们将仅通过它们的规范来指代它们）名称，但可以随意使用您喜欢的任何一个）。

以同样的方式，我们将定义一个列表推导式。如果我们用括号替换方括号，我们会得到一个由表达式产生的生成器。生成器表达式也可以直接传递给使用可迭代对象的函数，例如 sum() 和 max()：

```python
>>> [x**2 for x in range(10)]
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
>>> (x**2 for x in range(10))
<generator object <genexpr> at 0x...>
>>> sum(x**2 for x in range(10))
285
```

> 始终将生成器表达式而不是列表推导式传递给期望可迭代的函数，例如 min()、max() 和 sum()。 这更有效和 Pythonic。

之前的建议意味着尽量避免将列表传递给已经使用生成器的函数。 下一个代码中的示例是您想要避免的，并支持上一个清单中的方法：

```python
>>> sum([x**2 for x in range(10)])  # here the list can be avoided
```

而且，当然，您可以将生成器表达式分配给变量并在其他地方使用它（与推导式一样）。请记住，在这种情况下有一个重要的区别，因为我们在这里谈论的是生成器。一个列表可以被重复使用和迭代多次，但是一个生成器在它被迭代之后就会被耗尽。出于这个原因，请确保表达式的结果只被使用一次，否则你会得到意想不到的结果。

> 请记住，生成器在迭代后会耗尽，因为它们不会将所有数据保存在内存中。

一种常见的方法是在代码中创建新的生成器表达式。这样，第一个在迭代后会被耗尽，但随后会创建一个新的。以这种方式链接生成器表达式很有用，有助于节省内存并使代码更具表现力，因为它解决了不同步骤中的不同迭代。一种有用的场景是当您需要在可迭代对象上应用多个过滤器时；您可以通过使用多个充当链接过滤器的生成器表达式来实现这一点。

现在我们的工具箱中有一个新工具（迭代器），让我们看看如何使用它来编写更符合地道的代码。

## 惯用迭代

在本节中，我们将首先探讨一些在 Python 中处理迭代时会派上用场的习惯用法。这些代码秘籍将帮助我们更好地了解我们可以用生成器做的事情的类型（特别是在我们已经看过生成器表达式之后），以及如何解决与它们相关的典型问题。

一旦我们看到了一些习语，我们将继续更深入地探索 Python 中的迭代，分析使迭代成为可能的方法，以及可迭代对象的工作原理。

### 迭代的习语

我们已经熟悉内置的 enumerate() 函数，给定一个可迭代对象，它将返回另一个元素是元组的元素，其第一个元素是第二个元素的索引（对应于原始可迭代对象中的元素） )：

```python
>>> list(enumerate("abcdef"))
[(0, 'a'), (1, 'b'), (2, 'c'), (3, 'd'), (4, 'e'), (5, 'f')]
```

我们希望创建一个类似的对象，但以更底层的方式； 一个可以简单地创建一个无限序列。 我们想要一个对象，它可以从一开始就产生一系列数字，没有任何限制。

一个像下面这样简单的对象就可以做到这一点。 每次我们调用这个对象时，我们都会得到无限序列的下一个数字：

```python
class NumberSequence:
    def __init__(self, start=0):
        self.current = start
    def next(self):
        current = self.current
        self.current += 1
        return current
```

基于这个接口，我们必须通过显式调用它的 next() 方法来使用这个对象：

```python
>>> seq = NumberSequence()
>>> seq.next()
0
>>> seq.next()
1
>>> seq2 = NumberSequence(10)
>>> seq2.next()
10
>>> seq2.next()
11
```

但是使用这段代码，我们不能像我们想要的那样重构 enumerate() 函数，因为它的接口不支持在常规 Python for 循环上迭代，这也意味着我们不能将它作为参数传递给期望某些东西的函数 迭代。 请注意以下代码如何失败：

```python
>>> list(zip(NumberSequence(), "abcdef"))
Traceback (most recent call last):
  File "...", line 1, in <module>
TypeError: zip argument #1 must support iteration
```

问题在于 NumberSequence 不支持迭代。 为了解决这个问题，我们必须通过实现魔术方法 \_\_iter\_\_() 使对象成为可迭代对象。 我们还改变了之前的 next() 方法，通过使用 \_\_next\_\_ 魔术方法，使对象成为迭代器：

```python
class SequenceOfNumbers:
    def __init__(self, start=0):
        self.current = start
    def __next__(self):
        current = self.current
        self.current += 1
        return current
    def __iter__(self):
        return self
```

这有一个好处——我们不仅可以迭代元素，而且我们甚至不再需要 .next() 方法，因为 \_\_next\_\_() 允许我们使用 next() 内置函数：

```python
>>> list(zip(SequenceOfNumbers(), "abcdef"))
[(0, 'a'), (1, 'b'), (2, 'c'), (3, 'd'), (4, 'e'), (5, 'f')]
>>> seq = SequenceOfNumbers(100)
>>> next(seq)
100
>>> next(seq)
101
```

这利用了迭代协议。 与我们在前几章探讨的上下文管理器协议类似，它由 \_\_enter\_\_ 和 \_\_exit\_\_ 方法组成，该协议依赖于 \_\_iter\_\_ 和 \_\_next\_\_ 方法。

在 Python 中使用这些协议有一个优势：每个了解 Python 的人都已经熟悉这个接口，所以有一种“标准契约”。 这意味着，不必定义您自己的方法并与团队（或任何潜在的代码读者）达成一致，这是您的代码使用的预期标准或协议（就像我们在第一个中自定义的 next() 方法一样） 例子）; Python 已经提供了一个接口并且已经有了一个协议。 我们只需要正确地实施它。

#### next() 函数

next() 内置函数会将可迭代对象推进到其下一个元素并返回它：

```python
>>> word = iter("hello")
>>> next(word)
'h'
>>> next(word)
'e'  # ...
```

如果迭代器没有更多要生成的元素，则会引发 StopIteration 异常：

```python
>>> ...
>>> next(word)
'o'
>>> next(word)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration
>>>
```

此异常表示迭代已结束并且没有更多元素可以使用。

如果我们希望处理这种情况，除了捕获 StopIteration 异常之外，我们还可以为该函数的第二个参数提供一个默认值。 如果提供它，它将是代替抛出 StopIteration 的返回值：

```python
>>> next(word, "default value")
'default value'
```

建议大部分时间使用默认值，以避免我们的程序在运行时出现异常。 如果我们绝对确定我们正在处理的迭代器不能为空，那么最好对其进行隐式（和有意），而不是依赖内置函数的副作用（即正确断言情况） ）。

next() 函数与生成器表达式结合使用非常有用，在我们想要查找满足特定条件的可迭代对象的第一个元素的情况下。 我们将在整章中看到这个习语的例子，但主要思想是使用这个函数而不是创建一个列表推导式然后获取它的第一个元素。

#### 使用生成器

之前的代码可以通过简单地使用生成器来显着简化。 生成器对象是迭代器。 这样，我们可以定义一个函数来根据需要生成值，而不是创建一个类：

```python
def sequence(start=0):
    while True:
        yield start
        start += 1
```

请记住，从我们的第一个定义开始，函数体中的 yield 关键字使其成为生成器。 因为它是一个生成器，所以像这样创建一个无限循环是完全没问题的，因为当这个生成器函数被调用时，它会运行所有代码，直到到达下一个 yield 语句。 它将产生它的价值并在那里暂停：

```python
>>> seq = sequence(10)
>>> next(seq)
10
>>> next(seq)
11
>>> list(zip(sequence(), "abcdef"))
[(0, 'a'), (1, 'b'), (2, 'c'), (3, 'd'), (4, 'e'), (5, 'f')]
```

这种差异可以看作是创建装饰器的不同方式的类比，正如我们在前一章中探讨的（使用函数对象）。在这里，我们也可以使用生成器函数或可迭代对象，如上一节所述。只要有可能，建议构建一个生成器，因为它在语法上更简单，因此更容易理解。

#### 迭代工具

使用可迭代对象的优势在于代码可以更好地与 Python 本身融合，因为迭代是该语言的关键组成部分。除此之外，我们可以充分利用 itertools 模块（ITER-01）。实际上，我们刚刚创建的 sequence() 生成器与 itertools.count() 非常相似。然而，我们能做的还有很多。

关于迭代器、生成器和迭代工具的最好的事情之一是它们是可以链接在一起的可组合对象。

例如，回到我们处理购买以获得一些指标的第一个示例，如果我们想要做同样的事情，但只针对超过某个阈值的那些值呢？解决这个问题的天真方法是在迭代时放置条件：

```python
# ...
    def process(self):
        for purchase in self.purchases:
            if purchase > 1000.0:
                ...
```

这不仅是非 Pythonic 的，而且也是僵化的（而且僵化是表示糟糕代码的特征）。它不能很好地处理变化。如果现在数字改变了怎么办？我们是否通过参数传递它？如果我们需要不止一个怎么办？如果条件不同（例如，小于）怎么办？我们传递一个 lambda 表达式吗？

这个对象不应该回答这些问题，它的唯一职责是在以数字表示的购买流上计算一组明确定义的指标。当然，答案是否定的。进行这样的更改将是一个巨大的错误（再次重申，干净的代码是灵活的，我们不想通过将此对象与外部因素耦合来使其僵化）。这些要求必须在其他地方解决。

最好让这个对象独立于它的客户。这个类的责任越少，它对更多的客户端就越有用，从而增加它被重用的机会。

我们不会更改此代码，而是将其保持原样，并假设新数据是根据该类的每个客户的任何要求进行过滤的。

例如，如果我们只想处理金额超过 1000 的前 10 次购买，我们将执行以下操作：

```python
>>> from itertools import islice
>>> purchases = islice(filter(lambda p: p > 1000.0, purchases), 10)
>>> stats = PurchasesStats(purchases).process()  # ...
```

以这种方式过滤没有内存惩罚，因为因为它们都是生成器，所以评估总是懒惰的。这给了我们思考的力量，好像我们一次过滤了整个集合然后将其传递给对象，但实际上并没有将所有内容都放入内存中。

请记住本章开头提到的内存和 CPU 使用率之间的权衡。虽然代码可能使用更少的内存，但它可能会占用更多的 CPU 时间，但在大多数情况下，这是可以接受的，当我们必须在保持代码可维护的同时处理内存中的大量对象时。

#### 通过迭代器简化代码

现在，我们将简要讨论一些可以借助迭代器以及偶尔使用 itertools 模块来改进的情况。在讨论了每个案例及其建议的优化之后，我们将用一个推论来结束每个点。

**反复迭代**

现在我们已经了解了有关迭代器的更多信息，并介绍了 itertools 模块，我们可以向您展示本章的第一个示例（用于计算有关某些购买的统计信息的示例）是如何显着简化的：

```python
def process_purchases(purchases):
    min_, max_, avg = itertools.tee(purchases, 3)
    return min(min_), max(max_), median(avg)
```

在这个例子中， itertools.tee 将原始迭代器拆分为三个新的迭代器。我们将使用其中的每一种来进行我们需要的不同类型的迭代，而无需重复购买的三个不同循环。

读者可以简单地验证，如果我们传递一个可迭代对象作为购买参数，这个对象只会被遍历一次（感谢 itertools.tee 函数 [TEE]），这是我们的主要要求。还可以验证此版本与我们原始实现的等效性。在这种情况下，不需要手动引发 ValueError 因为将空序列传递给 min() 函数将执行此操作。

> 如果您正在考虑在同一个对象上多次运行循环，请停下来思考 itertools.tee 是否有帮助。

itertools 模块包含许多有用的函数和很好的抽象，它们在处理 Python 中的迭代时会派上用场。它还包含有关如何以惯用方式解决典型迭代问题的好方法。作为一般建议，如果您正在考虑如何解决涉及迭代的特定问题，请查看此模块。即使答案不是字面上的，它也会是很好的灵感。

**嵌套循环**

在某些情况下，我们需要迭代多个维度，寻找一个值，而嵌套循环是第一个想法。当找到该值时，我们需要停止迭代，但 break 关键字并不完全起作用，因为我们必须从两个（或多个）for 循环中逃脱，而不仅仅是一个。

解决这个问题的方法是什么？一个标志信号逃生？不。引发异常？不，这将与标志相同，但更糟糕的是，因为我们知道异常不能用于控制流逻辑。将代码移动到一个较小的函数并返回它？关闭，但不完全。

答案是，只要有可能，将迭代展平为单个 for 循环。

这是我们希望避免的代码类型：

```python
def search_nested_bad(array, desired_value):
    coords = None
    for i, row in enumerate(array):
        for j, cell in enumerate(row):
            if cell == desired_value:
                coords = (i, j)
                break
        if coords is not None:
            break
    if coords is None:
        raise ValueError(f"{desired_value} not found")
    logger.info("value %r found at [%i, %i]", desired_value, *coords)
    return coords
```

这是它的简化版本，它不依赖于标志来表示终止，并且具有更简单、更紧凑的迭代结构：

```python
def _iterate_array2d(array2d):
    for i, row in enumerate(array2d):
        for j, cell in enumerate(row):
            yield (i, j), cell
def search_nested(array, desired_value):
    try:
        coord = next(
            coord
            for (coord, cell) in _iterate_array2d(array)
            if cell == desired_value
        )
    except StopIteration as e:
        raise ValueError(f"{desired_value} not found") from e
    logger.info("value %r found at [%i, %i]", desired_value, *coord)
    return coord
```

值得一提的是，创建的辅助生成器如何作为所需迭代的抽象工作。在这种情况下，我们只需要迭代两个维度，但如果我们需要更多，一个不同的对象可以处理这个，而客户端不需要知道它。这就是迭代器设计模式的本质，它在 Python 中是透明的，因为它自动支持迭代器对象，这是下一节将介绍的主题。

尝试使用尽可能多的抽象来尽可能地简化迭代，并尽可能地将循环展平。

希望这个例子能激发你的灵感，让你明白我们可以使用生成器来做更多的事情，而不仅仅是节省内存。我们可以利用迭代作为一种抽象。也就是说，我们不仅可以通过定义类或函数，还可以利用 Python 的语法来创建抽象。就像我们已经看到如何抽象出上下文管理器背后的一些逻辑一样（所以我们不知道在 with 语句下发生的事情的细节），我们可以对迭代器做同样的事情（所以我们可以忘记底层的for 循环的逻辑）。

这就是为什么我们将从下一节开始探索迭代器模式在 Python 中的工作原理。

#### Python 中的迭代器模式

在这里，我们将绕过生成器来更深入地了解 Python 中的迭代。生成器是可迭代对象的一个特例，但 Python 中的迭代超越了生成器，能够创建好的可迭代对象将使我们有机会创建更高效、紧凑和可读的代码。

在前面的代码清单中，我们看到了可迭代对象也是迭代器的例子，因为它们实现了 \_\_iter\_\_() 和 \_\_next\_\_() 魔术方法。虽然这通常很好，但并不严格要求它们总是必须实现这两种方法，这里我们将展示可迭代对象（实现 \_\_iter\_\_ 的对象）和迭代器（实现 \_\_next\_\_ 的对象）之间的细微差别。

我们还探讨了与迭代相关的其他主题，例如序列和容器对象。

**迭代界面**

一个可迭代对象是一个支持迭代的对象，在非常高的层次上，这意味着我们可以在它上面运行一个 for .. in ... 循环，并且它可以毫无问题地工作。但是，iterable 并不等同于 iterator。

一般来说，一个可迭代对象就是我们可以迭代的东西，它使用迭代器来做到这一点。这意味着在 \_\_iter\_\_ 魔术方法中，我们希望返回一个迭代器，即一个实现了 \_\_next\_\_() 方法的对象。

迭代器是一个对象，它只知道如何产生一系列值，一次一个，当它被已经探索过的内置 next() 函数调用时，而迭代器没有被调用，它只是被冻结，闲置直到它再次被调用以产生下一个值。从这个意义上说，生成器就是迭代器。

| 概念     | 魔法方法     | 注意事项                                                     |
| -------- | ------------ | ------------------------------------------------------------ |
| Iterable | \_\_iter\_\_ | 他们使用迭代器来构建迭代逻辑。<br/>这些对象可以在 for ... in ...: 循环中迭代。 |
| Iterator | \_\_next\_\_ | 定义一次生成一个值的逻辑。<br/>StopIteration 异常表示迭代结束。<br/>这些值可以通过内置的 next() 函数一一获取。 |

在下面的代码中，我们将看到一个不可迭代的迭代器对象示例——它只支持一次调用一个值。 在这里，名称序列只是指一系列连续的数字，而不是 Python 中的序列概念，我们将在后面探讨：

```python
class SequenceIterator:
    def __init__(self, start=0, step=1):
        self.current = start
        self.step = step
    def __next__(self):
        value = self.current
        self.current += self.step
        return value
```

请注意，我们可以一次获取一个序列的值，但我们无法遍历此对象（这是幸运的，否则会导致无限循环）：

```python
>>> si = SequenceIterator(1, 2)
>>> next(si)
1
>>> next(si)
3
>>> next(si)
5
>>> for _ in SequenceIterator(): pass
... 
Traceback (most recent call last):
  ...
TypeError: 'SequenceIterator' object is not iterable
```

错误消息很清楚，因为该对象没有实现 \_\_iter\_\_()。

仅出于解释目的，我们可以将迭代分离到另一个对象中（同样，让对象同时实现 \_\_iter\_\_ 和 \_\_next\_\_ 就足够了，但单独这样做将有助于澄清我们在此解释中试图提出的独特观点） .

**序列对象作为可迭代对象**

正如我们刚刚看到的，如果一个对象实现了 \_\_iter\_\_() 魔术方法，就意味着它可以在 for 循环中使用。虽然这是一个很棒的功能，但它并不是我们可以实现的唯一可能的迭代形式。当我们编写 for 循环时，Python 会尝试查看我们使用的对象是否实现了 \_\_iter\_\_，如果实现了，它将使用它来构建迭代，但如果没有，则有回退选项。

如果对象恰好是一个序列（意味着它实现了 \_\_getitem\_\_() 和 \_\_len\_\_() 魔术方法），它也可以被迭代。如果是这种情况，解释器将按顺序提供值，直到引发 IndexError 异常，这类似于前面提到的 StopIteration，也发出停止迭代的信号。

为了说明这种行为的唯一目的，我们将运行以下实验，该实验显示了在一系列数字上实现 map() 的序列对象：

```python
# generators_iteration_2.py
class MappedRange:
    """Apply a transformation to a range of numbers."""
    def __init__(self, transformation, start, end):
        self._transformation = transformation
        self._wrapped = range(start, end)
    def __getitem__(self, index):
        value = self._wrapped.__getitem__(index)
        result = self._transformation(value)
        logger.info("Index %d: %s", index, result)
        return result
    def __len__(self):
        return len(self._wrapped)
```

请记住，此示例仅旨在说明可以使用常规 for 循环迭代诸如此类的对象。 \_\_getitem\_\_ 方法中放置了一个日志记录行，用于探索在迭代对象时传递了哪些值，我们可以从以下测试中看到：

```python
>>> mr = MappedRange(abs, -10, 5)
>>> mr[0]
Index 0: 10
10
>>> mr[-1]
Index -1: 4
4
>>> list(mr)
Index 0: 10
Index 1: 9
Index 2: 8
Index 3: 7
Index 4: 6
Index 5: 5
Index 6: 4
Index 7: 3
Index 8: 2
Index 9: 1
Index 10: 0
Index 11: 1
Index 12: 2
Index 13: 3
Index 14: 4
[10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0, 1, 2, 3, 4]
```

提醒一下，重要的是要强调，虽然知道这一点很有用，但它也是对象未实现 __iter__ 时的回退机制，所以大多数时候我们会想通过思考诉诸这些方法关于创建适当的序列，而不仅仅是我们想要迭代的对象。

> 在考虑设计一个迭代对象时，应该选择一个合适的可迭代对象（使用 __iter__），而不是一个可以同时迭代的序列。

Iterables 是 Python 的重要组成部分，不仅因为它们为我们作为软件工程师提供的功能，还因为它们在 Python 的内部扮演着重要的角色。

我们在第 2 章 Pythonic 代码的异步代码简介中已经看到，如何阅读异步代码。现在我们也探索了 Python 中的迭代器，我们可以看到这两个概念是如何关联的。特别是，下一节将探索协程，我们将看到迭代器是如何成为它们的核心的。

## 协程

协程的想法是有一个函数，它的执行可以在给定的时间点暂停，稍后再恢复。通过拥有这种功能，程序可能能够暂停部分代码，以便分派其他内容进行处理，然后返回到原始点继续。

正如我们已经知道的，生成器对象是可迭代的。他们实现了 \_\_iter\_\_() 和 \_\_next\_\_()。这是由 Python 自动提供的，因此当我们创建一个生成器对象函数时，我们会得到一个可以通过 next() 函数迭代或推进的对象。

除了这个基本功能之外，它们还有更多方法，以便它们可以作为协程（PEP-342）工作。在这里，我们将探讨生成器如何演变为协程以支持异步编程的基础，然后在下一节深入探讨 Python 的新特性和涵盖异步编程的语法。

PEP-342 中添加的支持协程的基本方法如下：

- .close()
- .throw(ex_type[, ex_value[, ex_traceback]])
- .send(value)

Python 利用生成器来创建协程。因为生成器可以自然地暂停，所以它们是一个方便的起点。但是生成器还不够，因为它们最初被认为是这样，所以添加了这些方法。这是因为通常情况下，仅仅能够挂起部分代码是不够的；您还想与它通信（传递数据，并发出有关上下文变化的信号）。

通过更详细地探索每种方法，我们将能够更多地了解 Python 中协程的内部结构。在此之后，我将再次概括介绍异步编程的工作原理，但与第 2 章 Pythonic 代码中介绍的内容不同，这将与我们刚刚学到的内部概念相关。

### 生成器接口的方法

在本节中，我们将探讨上述每种方法的作用、工作原理以及预期如何使用。通过了解如何使用这些方法，我们将能够使用简单的协程。

稍后，我们将探索协程的更高级用法，以及如何委派给子生成器（协程）以重构代码，以及如何编排不同的协程。

#### close()

调用此方法时，生成器将收到 GeneratorExit 异常。如果它没有被处理，那么生成器将完成而不产生更多值，并且它的迭代将停止。

此异常可用于处理完成状态。通常，如果我们的协程进行某种资源管理，我们希望捕获此异常并使用该控制块释放协程持有的所有资源。它类似于使用上下文管理器或将代码放在异常控制的 finally 块中，但专门处理此异常使其更加明确。

在下面的示例中，我们有一个协程，它使用一个数据库处理程序对象，该对象保存与数据库的连接，并对其运行查询，按固定长度的页面流式传输数据（而不是一次读取所有可用内容） ：

```python
def stream_db_records(db_handler):
    try:
        while True:
            yield db_handler.read_n_records(10)
    except GeneratorExit:
        db_handler.close()
```

在每次调用生成器时，它将返回从数据库处理程序获取的 10 行，但是当我们决定明确完成迭代并调用 close() 时，我们还想关闭与数据库的连接：

```python
>>> streamer = stream_db_records(DBHandler("testdb"))
>>> next(streamer)
[(0, 'row 0'), (1, 'row 1'), (2, 'row 2'), (3, 'row 3'), ...]
>>> next(streamer)
[(0, 'row 0'), (1, 'row 1'), (2, 'row 2'), (3, 'row 3'), ...]
>>> streamer.close()
INFO:...:closing connection to database 'testdb'
```

> 在需要时使用生成器上的 close() 方法执行整理任务。

此方法旨在用于资源清理，因此当您无法自动执行此操作时（例如，如果您没有使用上下文管理器），您通常会使用它来手动释放资源。 接下来，我们将看到如何将异常传递给生成器。

#### throw(ex_type[, ex_value[, ex_traceback]])

此方法将在生成器当前挂起的行抛出异常。 如果生成器处理了发送的异常，则将调用该特定 except 子句中的代码； 否则，异常将传播给调用者。

在这里，我们对前面的示例稍作修改，以显示当我们将此方法用于协程处理的异常时和不使用此方法时的区别：

```python
class CustomException(Exception):
    """A type of exception that is under control."""
def stream_data(db_handler):
    while True:
        try:
            yield db_handler.read_n_records(10)
        except CustomException as e:
            logger.info("controlled error %r, continuing", e)
        except Exception as e:
            logger.info("unhandled error %r, stopping", e)
            db_handler.close()
            break
```

现在，接收 CustomException 是控制流的一部分，在这种情况下，生成器将记录一条信息性消息（当然，我们可以根据每种情况的业务逻辑对其进行调整），然后继续 到下一个 yield 语句，这是协程从数据库读取并返回该数据的行。

这个特定的例子处理所有异常，但如果最后一个块（除了 Exception:）不存在，结果将是生成器在生成器暂停的行（再次，yield）处引发，并且它将从 来电者那里：

```python
>>> streamer = stream_data(DBHandler("testdb"))
>>> next(streamer)
[(0, 'row 0'), (1, 'row 1'), (2, 'row 2'), (3, 'row 3'), (4, 'row 4'), ...]
>>> next(streamer)
[(0, 'row 0'), (1, 'row 1'), (2, 'row 2'), (3, 'row 3'), (4, 'row 4'), ...]
>>> streamer.throw(CustomException)
WARNING:controlled error CustomException(), continuing
[(0, 'row 0'), (1, 'row 1'), (2, 'row 2'), (3, 'row 3'), (4, 'row 4'), ...]
>>> streamer.throw(RuntimeError)
ERROR:unhandled error RuntimeError(), stopping
INFO:closing connection to database 'testdb'
Traceback (most recent call last):
  ...
StopIteration
```

当我们收到域中的异常时，生成器继续。然而，当它收到另一个意想不到的异常时，默认块在我们关闭与数据库的连接并完成迭代的地方捕获，这导致生成器被停止。正如我们从引发的 StopIteration 中看到的那样，此生成器无法进一步迭代。

#### send(value)

在前面的例子中，我们创建了一个简单的生成器，它从数据库中读取行，当我们希望完成它的迭代时，这个生成器释放了链接到数据库的资源。这是使用生成器提供的其中一种方法 (close()) 的一个很好的例子，但我们可以做的还有更多。

对生成器的观察是它从数据库中读取固定数量的行。

我们想对这个数字 (10) 进行参数化，以便我们可以在不同的调用中更改它。不幸的是，next() 函数没有为我们提供选项。但幸运的是，我们有 send()：

```python
def stream_db_records(db_handler):
    retrieved_data = None
    previous_page_size = 10
    try:
        while True:
            page_size = yield retrieved_data
            if page_size is None:
                page_size = previous_page_size
            previous_page_size = page_size
            retrieved_data = db_handler.read_n_records(page_size)
    except GeneratorExit:
        db_handler.close()
```

这个想法是我们现在已经使协程能够通过 send() 方法从调用者接收值。 这个方法是真正区分生成器和协程的方法，因为当使用它时，这意味着 yield 关键字将出现在语句的右侧，并且它的返回值将被分配给其他东西。

在协程中，我们通常会发现yield关键字以如下形式使用：

```python
receive = yield produced
```

在这种情况下，yield 会做两件事。 它将生产返回给调用者，调用者将在下一轮迭代中获取它（例如，在调用 next() 之后），并在那里暂停。 稍后，调用者将希望使用 send() 方法将值发送回协程。 该值将成为 yield 语句的结果，在本例中分配给名为 receive 的变量。

将值发送到协程仅在此协程在 yield 语句处挂起时才有效，等待产生某些东西。 为此，协程必须提前到该状态。 唯一的方法是调用 next() 。 这意味着在向协程发送任何内容之前，这必须至少通过 next() 方法进行一次。 如果不这样做将导致异常：

```python
>>> def coro():
...     y = yield
...
>>> c = coro()
>>> c.send(1)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
TypeError: can't send non-None value to a just-started generator
>>>
```

在向协程发送任何值之前，请始终记住通过调用 next() 来推进协程。

回到我们的例子。我们正在改变元素的生成或流式传输方式，使其能够接收预期从数据库读取的记录长度。

我们第一次调用 next() 时，生成器将前进到包含 yield 的行；它将为调用者提供一个值（无，在变量中设置），并且它会在那里挂起）。从那里，我们有两个选择。如果我们选择通过调用 next() 来推进生成器，将使用默认值 10，它会像往常一样继续。这是因为调用 next() 在技术上与 send(None) 相同，但这包含在 if 语句中，该语句将处理我们之前设置的值。

另一方面，如果我们决定通过 send(<value>) 提供一个显式值，则该值将成为 yield 语句的结果，该结果将分配给包含要使用的页面长度的变量，即，反过来，将用于从数据库中读取。

连续调用将具有此逻辑，但重要的一点是，现在我们可以在迭代中间随时动态更改要读取的数据长度。

现在我们了解了之前的代码是如何工作的，大多数 Pythonistas 会期望它的简化版本（毕竟，Python 也是关于简洁、干净和紧凑的代码）：

```python
def stream_db_records(db_handler):
    retrieved_data = None
    page_size = 10
    try:
        while True:
            page_size = (yield retrieved_data) or page_size
            retrieved_data = db_handler.read_n_records(page_size)
    except GeneratorExit:
        db_handler.close()
```

这个版本不仅更紧凑，而且更好地说明了这个想法。 yield 周围的括号更清楚地表明它是一个语句（把它想象成一个函数调用），并且我们正在使用它的结果将它与之前的值进行比较。

这正如我们所期望的那样工作，但我们始终必须记住在向其发送任何数据之前推进协程。 如果我们忘记调用第一个 next()，我们会得到一个 TypeError。 出于我们的目的，可以忽略此调用，因为它不会返回我们将使用的任何内容。

如果我们可以在协程创建后直接使用它会很好，而不必记住第一次调用 next() ，每次我们要使用它。 一些作者 (PYCOOK) 设计了一个有趣的装饰器来实现这一点。 这个装饰器的想法是推进协程，所以下面的定义自动工作：

```python
@prepare_coroutine
def auto_stream_db_records(db_handler):
    retrieved_data = None
    page_size = 10
    try:
        while True:
            page_size = (yield retrieved_data) or page_size
            retrieved_data = db_handler.read_n_records(page_size)
    except GeneratorExit:
        db_handler.close()

>>> streamer = auto_stream_db_records(DBHandler("testdb"))
>>> len(streamer.send(5))
5
```

请记住，这些是协程如何在 Python 中工作的基础。通过遵循这些示例，您将了解在使用协程时 Python 中实际发生的情况。然而，在现代 Python 中，您通常不会自己编写这些类型的协程，因为有新的语法可用（我们已经提到过，但我们将重新审视它们与我们刚刚看到的想法之间的关系）。

在开始使用新的语法功能之前，我们需要探索协程在其附加功能方面的最后一次跳跃，以弥补缺失的差距。之后，我们将能够理解异步编程中使用的每个关键字和语句背后的含义。

### 更高级的协程

至此，我们对协程有了更好的理解，可以创建简单的协程来处理小任务。我们可以说，这些协程实际上只是更高级的生成器（没错，协程只是花哨的生成器），但是，如果我们真的想开始支持更复杂的场景，我们通常必须进行设计并发处理许多协程，并且需要更多功能。

在处理很多协程的时候，我们发现了新的问题。随着我们应用程序的控制流变得越来越复杂，我们希望在堆栈（以及异常）上下传递值，能够从我们可能在任何级别调用的子协程中捕获值，最后，调度多个协程朝着共同的目标奔跑。

为了让事情更简单，生成器必须再次扩展。这就是 PEP-380 通过更改生成器的语义以便它们可以返回值并通过从构造中引入新的收益来解决的问题。

#### 在协程中返回值

正如本章开头所介绍的，迭代是一种对可迭代对象多次调用 next() 直到引发 StopIteration 异常的机制。

到目前为止，我们一直在探索生成器的迭代特性——我们一次生成一个值，并且一般来说，我们只关心在 for 循环的每一步生成的每个值。这是一个非常合乎逻辑的思考生成器的方式，但是协程有不同的想法；尽管它们在技术上是生成器，但它们的构想并不是为了迭代，而是为了暂停代码的执行，直到稍后恢复。

这是一个有趣的挑战；当我们设计协程时，我们通常更关心挂起状态而不是迭代（并且迭代协程是一种奇怪的情况）。挑战在于很容易将它们混合在一起。这是因为技术实现细节； Python 中对协程的支持建立在生成器之上。

如果我们想使用协程来处理一些信息并暂停其执行，将它们视为轻量级线程（或绿色线程，因为它们在其他平台中被称为）是有意义的。在这种情况下，如果它们可以返回值就很有意义，就像调用任何其他常规函数一样。

但是让我们记住生成器不是常规函数，因此在生成器中，构造 value = generator() 除了创建生成器对象外不会做任何事情。使生成器返回值的语义是什么？它必须在迭代完成之后。

当生成器返回一个值时，它的迭代会立即停止（不能再迭代了）。为了保留语义，仍会引发 StopIteration 异常，并且要返回的值存储在异常对象中。捕获它是调用者的责任。

在下面的示例中，我们将创建一个简单的生成器，该生成器生成两个值，然后返回第三个值。请注意我们必须如何捕获异常才能获取此值，以及如何将其精确存储在名为 value 的属性下的异常中：

```python
>>> def generator():
...     yield 1
...     yield 2
...     return 3
... 
>>> value = generator()
>>> next(value)
1
>>> next(value)
2
>>> try:
...     next(value)
... except StopIteration as e:
...     print(f">>>>>> returned value: {e.value}")
... 
>>>>>> returned value: 3
```

稍后我们将看到，这种机制用于使协程返回值。在 PEP-380 之前，这没有任何意义，任何在生成器中包含 return 语句的尝试都被视为语法错误。但是现在的想法是，当迭代结束时，我们想要返回一个最终值，提供它的方法是将它存储在迭代结束时引发的异常中（StopIteration）。这可能不是最干净的方法，但它完全向后兼容，因为它不会改变生成器的接口。

#### 委托给更小的协程——'yield from' 语法

前面的特性很有趣，因为它为协程（生成器）开辟了许多新的可能性，现在它们可以返回值。但是如果没有适当的语法支持，这个特性本身就不会那么有用，因为以这种方式捕获返回值有点麻烦。

这是 yield from 语法的主要特征之一。除其他事项外（我们将详细回顾），它可以收集子生成器返回的值。请记住，我们说过在生成器中返回数据很好，但不幸的是，将语句编写为 value = generator() 不起作用？好吧，将它们写为 value = yield from generator() 会。

**最简单的使用 yield from**

在最基本的形式中，新的 yield from 语法可用于将嵌套 for 循环中的生成器链接到一个单独的循环中，最终将生成一个包含连续流中所有值的单个字符串。

一个规范的例子是关于从标准库创建一个类似于 itertools.chain() 的函数。这是一个非常好的函数，因为它允许您传递任意数量的可迭代对象，并将它们一起返回到一个流中。

天真的实现可能如下所示：

```python
def chain(*iterables):
    for it in iterables:
        for value in it:
            yield value
```

它接收可变数量的可迭代对象，遍历所有可迭代对象，并且由于每个值都是可迭代的，因此它支持 for... in.. 构造，因此我们有另一个 for 循环来获取每个特定可迭代对象中的每个值，即 由调用函数产生。

这在多种情况下可能会有帮助，例如将生成器链接在一起或尝试迭代通常无法一次性比较的事物（例如带有元组的列表等）。

然而，yield from 语法允许我们走得更远，避免嵌套循环，因为它能够直接从子生成器生成值。 在这种情况下，我们可以像这样简化代码：

```python
def chain(*iterables):
    for it in iterables:
        yield from it
```

请注意，对于这两种实现，生成器的行为完全相同：

```python
>>> list(chain("hello", ["world"], ("tuple", " of ", "values.")))
['h', 'e', 'l', 'l', 'o', 'world', 'tuple', ' of ', 'values.']
```

这意味着我们可以在任何其他可迭代对象上使用 yield from，并且它会像顶级生成器（即 yield from 使用的生成器）本身生成这些值一样工作。

这适用于任何可迭代对象，甚至生成器表达式也不例外。 现在我们已经熟悉了它的语法，让我们看看如何编写一个简单的生成器函数来生成一个数字的所有幂（例如，如果提供了 all_powers(2, 3)，它将必须生成 2^ 0, 2^1,... 2^3)：

```python
def all_powers(n, pow):
    yield from (n ** i for i in range(pow + 1))
```

虽然这稍微简化了语法，但节省一行 for 语句并不是一个很大的优势，并且不会证明向语言添加这样的更改是合理的。

事实上，这实际上只是一个副作用，构建收益的真正存在理由是我们将在以下两节中探讨的内容。

**捕获子生成器返回的值**

在下面的示例中，我们有一个生成器，它调用另外两个嵌套生成器，按顺序生成值。 这些嵌套生成器中的每一个都返回一个值，我们将看到顶级生成器如何能够有效地捕获返回值，因为它通过 yield from 调用内部生成器：

```python
def sequence(name, start, end):
    logger.info("%s started at %i", name, start)
    yield from range(start, end)
    logger.info("%s finished at %i", name, end)
    return end
def main():
    step1 = yield from sequence("first", 0, 5)
    step2 = yield from sequence("second", step1, 10)
    return step1 + step2
```

这是在迭代时可能在 main 中执行代码：

```python
>>> g = main()
>>> next(g)
INFO:generators_yieldfrom_2:first started at 0
0
>>> next(g)
1
>>> next(g)
2
>>> next(g)
3
>>> next(g)
4
>>> next(g)
INFO:generators_yieldfrom_2:first finished at 5
INFO:generators_yieldfrom_2:second started at 5
5
>>> next(g)
6
>>> next(g)
7
>>> next(g)
8
>>> next(g)
9
>>> next(g)
INFO:generators_yieldfrom_2:second finished at 10
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration: 15
```

第一行主代表进入内部生成器，并产生值，直接从中提取它们。正如我们已经看到的，这并不是什么新鲜事。但请注意，sequence() 生成器函数如何返回结束值，该值在第一行中分配给名为 step1 的变量，以及如何在该生成器的以下实例开始时正确使用该值。

最后，另一个生成器也返回第二个结束值 (10)，主生成器依次返回它们的总和 (5+10=15)，这是我们在迭代停止后看到的值。

> 我们可以使用 yield from 来捕获协程完成处理后的最后一个值。

通过此示例和上一节中介绍的示例，您可以了解构造产生的收益在 Python 中的作用。构造的 yield 将采用生成器，并将其迭代转发到下游，但一旦完成，它将捕获其 StopIteration 异常，获取它的值，并将该值返回给调用者函数。 StopIteration 异常的 value 属性成为语句的结果。

这是一个强大的构造，因为结合下一节的主题（如何从子生成器发送和接收上下文信息），这意味着协程可以采用类似于线程的形式。

向子生成器发送数据和从子生成器接收数据

现在，我们将看到 yield from 语法的另一个不错的特性，这可能是它发挥全部功能的原因。正如我们在探索充当协程的生成器时已经介绍的那样，我们知道我们可以发送值并向它们抛出异常，在这种情况下，协程要么接收值以进行内部处理，要么必须处理相应地例外。

如果我们现在有一个协程可以委托给其他协程（例如在前面的示例中），我们也希望保留此逻辑。必须手动执行此操作将非常复杂（如果我们没有自动处理此问题，您可以查看 PEP-380 中描述的代码）。

为了说明这一点，让我们保持与前面的示例（调用其他内部生成器）相同的顶级生成器（main）未修改，但让我们修改内部生成器，使其能够接收值并处理异常。

代码可能不是惯用的，只是为了展示这种机制是如何工作的：

```python
def sequence(name, start, end):
    value = start
    logger.info("%s started at %i", name, value)
    while value < end:
        try:
            received = yield value
            logger.info("%s received %r", name, received)
            value += 1
        except CustomException as e:
            logger.info("%s is handling %s", name, e)
            received = yield "OK"
    return end
```

现在，我们将调用主协程，不仅通过迭代它，而且通过提供值和抛出异常来查看它们在序列中是如何处理的：

```python
>>> g = main()
>>> next(g)
INFO: first started at 0
0
>>> next(g)
INFO: first received None
1
>>> g.send("value for 1")
INFO: first received 'value for 1'
2
>>> g.throw(CustomException("controlled error"))
INFO: first is handling controlled error
'OK'
... # advance more times
INFO:second started at 5
5
>>> g.throw(CustomException("exception at second generator"))
INFO: second is handling exception at second generator
'OK'
```

这个例子告诉我们很多不同的事情。请注意，我们从不向序列发送值，而只向 main 发送值，即便如此，接收这些值的代码还是嵌套生成器。即使我们从来没有明确地发送任何东西到序列，它正在接收数据，因为它是由 yield from 传递的。

主协程在内部调用另外两个协程，产生它们的值，并且它将在其中任何一个的特定时间点暂停。当它在第一个停止时，我们可以看到日志告诉我们它是接收我们发送的值的协程实例。当我们向它抛出异常时也会发生同样的情况。当第一个协程完成时，它返回在名为 step1 的变量中分配的值，并作为第二个协程的输入传递，第二个协程将执行相同的操作（它将相应地处理 send() 和 throw() 调用）。

每个协程产生的值也是如此。当我们处于任何给定步骤时，调用 send() 的返回对应于子协程（主协程当前挂起的协程）产生的值。当我们抛出一个正在处理的异常时，序列协程会产生值 OK，该值会传播到被调用的协程（main），然后最终会在 main 的调用者处结束。

正如预期的那样，这些方法与 yield from 一起为我们提供了许多新功能（类似于线程的东西）。这为异步编程打开了大门，我们将在接下来进行探讨。

## 异步编程

使用到目前为止我们所看到的结构，我们可以在 Python 中创建异步程序。这意味着我们可以创建具有许多协程的程序，安排它们按特定顺序工作，并在对每个协程调用 yield from 后暂停时在它们之间切换。

我们可以从中获得的主要优势是以非阻塞方式并行化 I/O 操作的可能性。我们需要的是一个低级生成器（通常由第三方库实现），它知道在协程挂起时如何处理实际的 I/O。这个想法是让协程影响暂停，以便我们的程序可以同时处理另一个任务。应用程序取回控制权的方式是通过 yield from 语句，该语句将挂起并向调用者生成一个值（如我们之前看到的示例中，当我们使用此语法更改程序的控制流时） .

这大致是异步编程在 Python 中工作了好几年的方式，直到决定需要更好的语法支持。

协程和生成器在技术上是相同的这一事实引起了一些混淆。在语法上（和技术上），它们是相同的，但在语义上，它们是不同的。当我们想要实现高效迭代时，我们会创建生成器。我们通常以运行非阻塞 I/O 操作为目标来创建协程。

虽然这种差异很明显，但 Python 的动态特性仍然允许开发人员混合这些不同类型的对象，最终在程序的最后阶段出现运行时错误。请记住，在 yield from 语法的最简单和最基本的形式中，我们在可迭代对象上使用了这种构造（我们创建了一种应用于字符串、列表等的链函数）。这些对象都不是协程，它仍然有效。然后，我们看到我们可以有多个协程，使用 yield from 发送值（或异常），并返回一些结果。这显然是两个截然不同的用例；但是，如果我们按照以下语句写一些东西：

```python
result = yield from iterable_or_awaitable()
```

不清楚 iterable_or_awaitable 返回什么。它可以是一个简单的可迭代对象，例如字符串，并且在语法上可能仍然是正确的。或者，它可能是一个实际的协程。这个错误的代价将在很晚的时候在运行时支付。

因此，必须扩展 Python 中的类型系统。在 Python 3.5 之前，协程只是应用了 @coroutine 装饰器的生成器，它们将使用 yield from 语法进行调用。现在，Python 解释器识别出一种特定类型的对象，即协程。

这种变化也预示着语法的变化。引入了 await 和 async def 语法。前者旨在用于代替 yield from，并且它仅适用于可等待对象（协程恰好是）。尝试使用不尊重 awaitable 接口的东西调用 await 将引发异常（这是一个很好的示例，说明接口如何帮助实现更可靠的设计，防止运行时错误）。

async def 是定义协程的新方法，取代了前面提到的装饰器，这实际上创建了一个对象，当被调用时，它将返回一个协程的实例。与调用生成器函数时一样，解释器将返回一个生成器对象，当您调用用 async def 定义的对象时，它会给您一个具有 \_\_await\_\_ 方法的协程对象，因此可以使用在 await 表达式中。

无需深入探讨 Python 中异步编程的所有细节和可能性，我们可以说，尽管有新的语法和新类型，但这与我们在本章中介绍的概念并没有本质上的不同。

在 Python 中进行异步编程背后的想法是有一个事件循环（通常是 asyncio，因为它包含在标准库中，但还有许多其他的工作方式相同）来管理一系列协程。这些协程属于事件循环，事件循环将根据其调度机制调用它们。当每一个运行时，它都会调用我们的代码（根据我们在我们编写的协程中定义的逻辑），当我们想要控制回事件循环时，我们调用 await <coroutine>，它将处理异步任务。事件循环将恢复，而另一个协程将在该操作继续运行时发生。

这种机制代表了异步编程如何在 Python 中工作的基础知识。你可以认为为协程添加的新语法（async def / await）只是一个 API，让你以一种将被事件循环调用的方式编写代码。默认情况下，该事件循环通常是 asyncio，因为它是标准库中的一个，但任何与 API 匹配的事件循环系统都可以工作。这意味着您可以使用 uvloop (https://github.com/MagicStack/uvloop) 和 trio (https://github.com/python-trio/trio) 之类的库，并且代码的工作方式相同。你甚至可以注册你自己的事件循环，它也应该同样工作（前提是符合 API）。

在实践中，还有更多的特殊性和边缘情况超出了本书的范围。然而，值得一提的是，这些概念与本章介绍的思想相关，并且这个领域是另一个展示生成器作为语言核心概念的地方，因为在它们之上构建了许多东西。

### 神奇的异步方法

我在前面的章节中已经说明了（希望能说服你），只要有可能，我们就可以利用 Python 中的魔法方法来使我们创建的抽象与语言的语法自然融合，这样可以更好地实现 ，更紧凑，也许更干净的代码。

但是如果我们需要在这些方法中的任何一个上调用协程会发生什么？ 如果我们必须在函数中调用 await，那意味着函数本身必须是一个协程（用 async def 定义），否则会出现语法错误。

但是，这如何与当前的语法和魔术方法一起工作？ 它没有。 我们需要新的语法和新的魔法方法，以便使用异步编程。 好消息是它们与之前的类似。

以下是新魔术方法的摘要以及它们与新语法的关系。

| 概念       | 魔法方法                             | 语法                                     |
| ---------- | ------------------------------------ | ---------------------------------------- |
| 上下文管理 | \_\_aenter\_\_<br/>\_\_aexit\_\_     | async with async_cm() as x:<br/><br/>... |
| 迭代器     | \_\_aiter\_\_<br/><br/>\_\_anext\_\_ | async for e in aiter:<br/><br/>...       |

PEP-492 (https://www.python.org/dev/peps/pep-0492/) 中提到了这种新语法。

异步上下文管理器
这个想法很简单：如果我们要使用上下文管理器但需要在其上调用协程，我们不能使用普通的 \_\_enter\_\_ 和 \_\_exit\_\_ 方法，因为它们被定义为常规函数，因此我们需要使用新的\_\_aenter\_\_ 和 \_\_aexit\_\_ 协程方法。而不是仅仅使用 with 来调用它，我们必须使用 async with。

在 contextlib 模块中甚至还有一个 @asynccontextmanager 装饰器可用，以与之前所示的相同方式创建异步上下文管理器。

异步上下文管理器的 async with 语法以类似的方式工作：当进入上下文时，\_\_aenter\_\_ 协程被自动调用，当它被退出时，\_\_aexit\_\_ 将触发。甚至可以在同一个 async with 语句中对多个异步上下文管理器进行分组，但不可能将它们与常规的混合使用。尝试使用带有 async with 语法的常规上下文管理器将失败并显示 AttributeError。

如果适用于异步编程，我们第 2 章 Pythonic 代码中的示例将类似于以下代码：

```python
@contextlib.asynccontextmanager
async def db_management():
    try:
        await stop_database()
        yield
    finally:
        await start_database()
```

此外，如果我们想要使用多个上下文管理器，我们可以这样做，例如：

```python
@contextlib.asynccontextmanager
async def metrics_logger():
    yield await create_metrics_logger()
 
 
async def run_db_backup():
    async with db_management(), metrics_logger():
        print("Performing DB backup...")
```

正如您所期望的，contextlib 模块提供了抽象基类 AbstractAsyncContextManager，它需要实现 \_\_aenter\_\_ 和 \_\_aexit\_\_ 方法。

#### 其他魔法方法

其余的魔法方法会发生什么？他们都得到了他们的异步对应物吗？不，但我想指出一点：它不应该被需要。

请记住，实现干净的代码部分是为了确保您在代码中正确分配职责并将事物放置在适当的位置。举个例子，如果您正在考虑在 \_\_getattr\_\_ 方法中调用协程，那么您的设计中可能存在一些问题，因为该协程可能应该有更好的地方。

我们等待的协程用于让我们的部分代码并发运行，因此它们通常与管理的外部资源有关，而我们放入其余魔术方法（\_\_getitem\_\_、\_\_getattr\_\_ 等）的逻辑应该是对象面向代码，或者可以仅根据该对象的内部表示来解析的代码。

出于同样的原因（并遵循良好的设计实践），将 \_\_init\_\_ 设为协程并不好，因为我们通常希望可以安全地初始化而没有副作用的轻量级对象。更好的是，我们已经介绍了使用依赖注入的好处，因此更有理由不想要异步初始化方法：我们的对象应该使用已经初始化的依赖项。

就本章而言，上表的第二种情况异步迭代更有意义，因此我们将在下一节中对其进行探讨。

异步迭代 (async for) 的语法适用于任何异步迭代器，无论它是由我们创建的（我们将在下一节中看到如何做），或者它是否是一个异步生成器（我们将在之后的部分）。

### 异步迭代

与我们在本章开头看到的迭代器对象（即支持使用 Python 的内置 for 循环进行迭代的对象）相同的方式，我们可以以异步方式执行相同的操作。

想象一下，我们想创建一个迭代器来抽象我们从外部源（如数据库）读取数据的方式，但提取数据本身的部分是一个协程，所以我们不能在已经熟悉的 \_\_next\_\_ 期间调用它操作如前。这就是为什么我们需要使用 \_\_anext\_\_ 协程。

以下示例以简单的方式说明了如何实现这一点。不考虑外部依赖或任何其他意外的复杂性，我们将重点关注使此类操作成为可能的方法，以便研究它们：

```python
import asyncio
import random
 
 
async def coroutine():
    await asyncio.sleep(0.1)
    return random.randint(1, 10000)
 
 
class RecordStreamer:
    def __init__(self, max_rows=100) -> None:
        self._current_row = 0
        self._max_rows = max_rows
 
    def __aiter__(self):
        return self
 
    async def __anext__(self):
        if self._current_row < self._max_rows:
            row = (self._current_row, await coroutine())
            self._current_row += 1
            return row
        raise StopAsyncIteration
```

第一个方法 \_\_aiter\_\_ 用于指示对象是异步迭代器。 就像在同步版本中一样，大多数时候返回 self 就足够了，因此它不需要是一个协程。

但另一方面，\_\_anext\_\_ 正是我们代码中异步逻辑所在的部分，因此它需要成为初学者的协程。 在这种情况下，我们正在等待另一个协程以返回要返回的部分数据。

它还需要一个单独的异常来通知迭代结束，在这种情况下，称为 StopAsyncIteration。

此异常以类似的方式工作，只是它用于异步循环。 遇到时，解释器将完成循环。

此类对象可以按以下形式使用：

```python
async for row in RecordStreamer(10):
    ...
```

您可以清楚地看到这与我们在本章开头探讨的同步版本有何相似之处。 但一个重要的区别是，正如我们所期望的，next() 函数不会在这个对象上工作（它毕竟没有实现 __next__），因此将异步生成器推进一个位置将需要不同的习惯用法。

可以通过执行以下操作将异步迭代器推进一个位置：

```python
await async_iterator.__anext__()
```

但是更有趣的构造，比如我们之前看到的关于使用 next() 函数处理生成器表达式以搜索满足特定条件的第一个值的构造，将不被支持，因为它们无法处理异步 迭代器。

受上一个习惯用法的启发，我们可以使用异步迭代创建一个生成器表达式，然后从中获取第一个值。 更好的是，我们可以创建我们自己的这个函数版本来使用异步生成器，它可能如下所示：

```python
NOT_SET = object()
 
async def anext(async_generator_expression, default=NOT_SET):
    try:
        return await async_generator_expression.__anext__()
    except StopAsyncIteration:
        if default is NOT_SET:
            raise
        return default
```

从 Python 3.8 开始，asyncio 模块有一个很好的功能，允许我们直接从 REPL 与协程交互。 这样，我们就可以交互地测试之前的代码是如何工作的：

```python
$ python -m asyncio
>>> streamer = RecordStreamer(10)
>>> await anext(streamer)
(0, 5017)
>>> await anext(streamer)
(1, 5257)
>>> await anext(streamer)
(2, 3507)
...
>>> await anext(streamer)
(9, 5440)
>>> await anext(streamer)
Traceback (most recent call last):
    ...
    raise StopAsyncIteration
StopAsyncIteration
>>>
```

您会注意到它在界面和行为方面都类似于原始的 next() 函数。

现在我们知道如何在异步编程中使用迭代，但我们可以做得更好。大多数时候我们只需要一个生成器而不是一个完整的迭代器对象。生成器的优势在于它们的语法使它们更易于编写和理解，因此在下一节中，我将提到如何为异步程序创建生成器。

### 异步生成器

在 Python 3.6 之前，上一节中探讨的功能是在 Python 中实现异步迭代的唯一方法。由于我们在前几节中探讨的协程和生成器的复杂性，尝试在协程中使用 yield 语句并未完全定义，因此是不允许的（例如，将 yield 尝试挂起协程，或为呼叫者？）。

PEP-525 (https://www.python.org/dev/peps/pep-0525/) 中引入了异步生成器。

在此 PEP 中解决了在协程中使用 yield 关键字的问题，现在允许使用，但具有不同且明确的含义。与我们看到的第一个协程示例不同，在正确定义的协程中（使用 async def）yield 并不意味着挂起或暂停该协程的执行，而是为调用者生成一个值。这是一个异步生成器：与我们在本章开头看到的生成器相同，但可以以异步方式使用（意味着它们可能在其定义中等待其他协程）。

异步生成器相对于迭代器的主要优势与常规生成器具有的优势相同；它们使我们能够以更紧凑的方式实现相同的目标。

正如承诺的那样，当使用异步生成器编写时，前面的示例看起来更紧凑：

```python
async def record_streamer(max_rows):
    current_row = 0
    while current_row < max_rows:
        row = (current_row, await coroutine())
        current_row += 1
        yield row
```

这感觉更接近于常规生成器，因为除了 async def / await 构造之外，结构是相同的。此外，您必须记住更少的细节（关于需要实现的方法和必须触发的正确异常），因此我建议您尽可能尝试使用异步生成器而不是迭代器。

我们的 Python 迭代和异步编程之旅到此结束。特别是，我们刚刚探讨的最后一个主题是它的巅峰之作，因为它涉及我们在本章中学到的所有概念。

## 总结

生成器在 Python 中无处不在。自从很久以前在 Python 中出现以来，它们被证明是一个很好的补充，可以使程序更高效，迭代更简单。

随着时间的流逝，需要将更复杂的任务添加到 Python 中，生成器再次帮助支持协程。

而且，虽然在 Python 中协程是生成器，但我们仍然不必忘记它们在语义上是不同的。生成器是基于迭代的思想创建的，而协程的目标是异步编程（在任何给定时间暂停和恢复我们程序的一部分的执行）。这种区别变得如此重要，以至于它使 Python 的语法（和类型系统）不断发展。

迭代和异步编程构成了 Python 编程的最后一个主要支柱。现在，是时候看看一切如何组合在一起，并将我们在过去几章中探索的所有这些概念付诸实践。这意味着到目前为止，您已经完全了解 Python 的功能。

现在是时候利用它为您带来好处了，所以在接下来的章节中，我们将看到如何将这些概念付诸实践，这些概念与软件工程的更一般思想有关，例如测试、设计模式和体系结构。

在下一章中，我们将通过探索单元测试和重构来开始我们旅程的新部分。

## 参考

以下是您可以参考的信息列表：

PEP-234：迭代器（https://www.python.org/dev/peps/pep-0234/）
PEP-255：简单生成器（https://www.python.org/dev/peps/pep-0255/）
ITER-01：Python 的 itertools 模块 (https://docs.python.org/3/library/itertools.html)
GoF：由 Erich Gamma、Richard Helm、Ralph Johnson 和 John Vlissides 编写的书《设计模式：可重用面向对象软件的元素》
PEP-342：通过增强生成器的协程 (https://www.python.org/dev/peps/pep-0342/)
PYCOOK：这本书由 Brian Jones 和 David Beazley 编写，名为 Python Cookbook: Recipes for Mastering Python 3，第三版
PY99：假线程（生成器、协程和延续）（https://mail.python.org/pipermail/python-dev/1999-July/000467.html）
CORO-01：协同例程（http://wiki.c2.com/?CoRoutine）
CORO-02：生成器不是协程 (http://wiki.c2.com/?GeneratorsAreNotCoroutines)
PEP-492：具有异步和等待语法的协程（https://www.python.org/dev/peps/pep-0492/）
PEP-525：异步生成器（https://www.python.org/dev/peps/pep-0525/）
TEE：itertools.tee 函数 (https://docs.python.org/3/library/itertools.html#itertools.tee)